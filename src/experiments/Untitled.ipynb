{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a149d002-8946-4ed8-b302-0655b6c90a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation\")\n",
    "\n",
    "from src.utils.rope_utils import random_masking_smart\n",
    "from src.models.components.vit_rope import select_freqs_cis\n",
    "from timm.models.vision_transformer import Mlp as Mlp\n",
    "from src.models.mae_rope_encoder import EncoderViTRoPE\n",
    "from src.models.mae_rope_decoder import DecoderViTRoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "cd2da5c6-4e6c-4095-b932-4615976c7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.models_v2 import (\n",
    "    vit_models,\n",
    "    Layer_scale_init_Block,\n",
    "    Attention,\n",
    ")\n",
    "\n",
    "class Flexible_RoPE_Layer_scale_init_Block(Layer_scale_init_Block):\n",
    "    # taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
    "    # with slight modifications\n",
    "\n",
    "    # Adjusted to work with FlexibleRoPEAttention.\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs[\"Attention_block\"] = FlexibleRoPEAttention\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x, freqs_cis, mask, nr_meta_tokens):\n",
    "        x = x + self.drop_path(\n",
    "            self.gamma_1\n",
    "            * self.attn(\n",
    "                self.norm1(x), freqs_cis=freqs_cis, mask=mask, nr_meta_tokens=nr_meta_tokens\n",
    "            )\n",
    "        )\n",
    "        x = x + self.drop_path(self.gamma_2 * self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class FlexibleRoPEAttention(Attention):\n",
    "    \"\"\"\n",
    "    Multi-head Attention block with rotary position embeddings.\n",
    "\n",
    "    Adjusted the RoPEAttention class to work with a variable number of prepended tokens,\n",
    "    e.g. one cls token and multiple mean tokens.\n",
    "\n",
    "    They are not taken into consideration when applying the rotary position embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, freqs_cis, mask, nr_meta_tokens):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        qkv = (\n",
    "            self.qkv(x)\n",
    "            .reshape(B, N, 3, self.num_heads, C // self.num_heads)\n",
    "            .permute(2, 0, 3, 1, 4)\n",
    "        )\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        q[:, :, nr_meta_tokens:], k[:, :, nr_meta_tokens:] = apply_rotary_emb(\n",
    "            q[:, :, nr_meta_tokens:], k[:, :, nr_meta_tokens:], freqs_cis=freqs_cis\n",
    "        )\n",
    "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    print(f\"[apply_rotary_emb] xq_.shape: {xq_.shape}\")\n",
    "    print(f\"[apply_rotary_emb] freqs_cis.shape: {freqs_cis.shape}\")\n",
    "    xq_prod = xq_ * freqs_cis\n",
    "    print(f\"[apply_rotary_emb] (xq_ * freqs_cis).shape: {xq_prod.shape}\")\n",
    "    xq_out = torch.view_as_real(xq_prod).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq).to(xq.device), xk_out.type_as(xk).to(xk.device)\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    print(\"[reshape_for_broadcast] freqs_cis.shape:\", freqs_cis.shape)\n",
    "    print(\"[reshape_for_broadcast] xq_.shape:\", x.shape)\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    if freqs_cis.shape == (x.shape[-2], x.shape[-1]):\n",
    "        shape = [d if i >= ndim - 2 else 1 for i, d in enumerate(x.shape)]\n",
    "    elif freqs_cis.shape == (x.shape[-3], x.shape[-2], x.shape[-1]):\n",
    "        shape = [d if i >= ndim - 3 else 1 for i, d in enumerate(x.shape)]\n",
    "    elif freqs_cis.shape == (x.shape[0], x.shape[-2], x.shape[-1]): #custom case\n",
    "        shape = [x.shape[0], 1, x.shape[-2], x.shape[-1]] \n",
    "\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "def random_masking_smart(x, mask_ratio, nr_meta_tokens):\n",
    "    B, N, D = x.shape\n",
    "\n",
    "    num_tokens_to_keep = int((N - nr_meta_tokens) * (1 - mask_ratio))\n",
    "\n",
    "    # indices we keep\n",
    "    rand_indices, _ = (\n",
    "        torch.rand(B, N - nr_meta_tokens, device=x.device)\n",
    "        .argsort(dim=1)[:, :num_tokens_to_keep]\n",
    "        .sort(dim=1)\n",
    "    )\n",
    "    rand_indices += nr_meta_tokens\n",
    "\n",
    "    # Add True values at positions we keep\n",
    "    mask = torch.zeros(B, N, dtype=torch.bool, device=x.device)\n",
    "    mask.scatter_(1, rand_indices, True)\n",
    "\n",
    "    # Fill mask[:, :nr_meta_tokens] with True (always keep metadata tokens)\n",
    "    mask[:, :nr_meta_tokens] = True\n",
    "\n",
    "    # Indices to restore in decoder\n",
    "    kept_indices = torch.nonzero(mask, as_tuple=True)[1].reshape(B, -1)\n",
    "    masked_indices = torch.nonzero(~mask, as_tuple=True)[1].reshape(B, -1)\n",
    "    ids_restore = torch.cat([kept_indices, masked_indices], dim=1).unsqueeze(-1).repeat(1, 1, D)\n",
    "    \n",
    "    return mask, ids_restore\n",
    "\n",
    "def random_masking(x, mask_ratio, nr_meta_tokens):\n",
    "    \"\"\"\n",
    "    Perform per-sample random masking by per-sample shuffling.\n",
    "    Per-sample shuffling is done by argsort random noise.\n",
    "    x: [N, L, D], sequence\n",
    "    \"\"\"\n",
    "    B, N, D = x.shape  # batch, length, dim\n",
    "    len_keep = int((N - nr_meta_tokens) * (1 - mask_ratio))\n",
    "    \n",
    "    noise = torch.rand(B, N - nr_meta_tokens, device=x.device)  # noise in [0, 1]\n",
    "    \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_shuffle += nr_meta_tokens\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "    print(\"ids_restore.shape\", ids_restore.shape)\n",
    "    print(ids_restore[0])\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([B, N], device=x.device)\n",
    "    mask[:, :len_keep] = 0\n",
    "    print(\"mask.shape\", mask.shape)\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "    print(\"mask.shape\", mask.shape)\n",
    "    \n",
    "    #return x_masked, mask, ids_restore\n",
    "    return mask, ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c97efc7-c39a-4e25-bf60-d93600f0ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==encoder pass====================================================================================================\n",
      "[forward_encoder] after random_masking_smart (x.shape): torch.Size([4, 66, 384]) (B, N, D)\n",
      "[forward_encoder] after random_masking_smart (mask.shape): torch.Size([4, 258]) (B, N)\n",
      "[forward_encoder] freqs_cis.shape: torch.Size([4, 64, 32]) (B, N, D // num_heads // 2)\n",
      "[reshape_for_broadcast] freqs_cis.shape: torch.Size([4, 64, 32])\n",
      "[reshape_for_broadcast] xq_.shape: torch.Size([4, 6, 64, 32])\n",
      "[apply_rotary_emb] xq_.shape: torch.Size([4, 6, 64, 32])\n",
      "[apply_rotary_emb] freqs_cis.shape: torch.Size([4, 1, 64, 32])\n",
      "[apply_rotary_emb] (xq_ * freqs_cis).shape: torch.Size([4, 6, 64, 32])\n",
      "[forward_encoder] after rope blocks: torch.Size([4, 66, 384]) (B, N, D)\n",
      "==decoder pass====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = 4, 1, 32, 2048\n",
    "win_size = 1\n",
    "nr_meta_patches = 2\n",
    "mask_ratio = 0.75\n",
    "\n",
    "x = torch.randn(B, h * w + nr_meta_patches, 384)\n",
    "\n",
    "def encoder(x, win_size, mask_ratio):\n",
    "\n",
    "    self = EncoderViTRoPE(channel_names_path=\"/home/maxihuber/eeg-foundation/src/data/components/channels_to_id.json\")\n",
    "    \n",
    "    B, C, D = x.shape\n",
    "    h, w = H // 16, W // 16\n",
    "    \n",
    "    # Keep for reconstruction loss\n",
    "    meta_patches = x[:, :nr_meta_patches, :]\n",
    "    \n",
    "    # Encoder: randomly mask some patches (exluding metadata patches)\n",
    "    x, mask = random_masking_smart(\n",
    "        x=x, mask_ratio=mask_ratio, nr_meta_tokens=nr_meta_patches\n",
    "    )\n",
    "    x = x[mask].view(B, -1, x.shape[-1])\n",
    "    print(\"[forward_encoder] after random_masking_smart (x.shape):\", x.shape, \"(B, N, D)\")\n",
    "    print(\"[forward_encoder] after random_masking_smart (mask.shape):\", mask.shape, \"(B, N)\")\n",
    "    \n",
    "    # Encoder: select correct rotation information for the attention layers\n",
    "    freqs_cis = select_freqs_cis(\n",
    "        self, self.encoder_freqs_cis, H, W, win_size, x.device\n",
    "    ).unsqueeze(0).repeat(B, 1, 1)\n",
    "    freqs_cis = freqs_cis[mask[:, nr_meta_patches:]].view(B, -1, freqs_cis.shape[-1])\n",
    "    print(\"[forward_encoder] freqs_cis.shape:\", freqs_cis.shape, \"(B, N, D // num_heads // 2)\")\n",
    "    \n",
    "    blk = Flexible_RoPE_Layer_scale_init_Block(\n",
    "        dim=384,\n",
    "        num_heads=6,\n",
    "        mlp_ratio=4,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        act_layer=nn.GELU,\n",
    "        Attention_block=FlexibleRoPEAttention,\n",
    "        Mlp_block=Mlp,\n",
    "        init_values=1e-4,\n",
    "    )\n",
    "    x = blk(x, freqs_cis=freqs_cis, mask=mask, nr_meta_tokens=nr_meta_patches)\n",
    "    print(\"[forward_encoder] after rope blocks:\", x.shape, \"(B, N, D)\")\n",
    "\n",
    "    return x, meta_patches, mask, nr_meta_patches\n",
    "\n",
    "def decoder(x, nr_meta_patches, H, W, win_size):\n",
    "    \n",
    "    self = DecoderViTRoPE(channel_names_path=\"/home/maxihuber/eeg-foundation/src/data/components/channels_to_id.json\")\n",
    "\n",
    "    x = torch.randn(x.shape[-3], x.shape[-2], 512)\n",
    "    B, N, D = x.shape\n",
    "\n",
    "    freqs_cis = select_freqs_cis(\n",
    "        self, self.decoder_freqs_cis, H, W, win_size, x.device\n",
    "    )\n",
    "\n",
    "    # Insert self.mask_token at masked positions\n",
    "   \n",
    "    blk = Flexible_RoPE_Layer_scale_init_Block(\n",
    "        dim=512,\n",
    "        num_heads=16,\n",
    "        mlp_ratio=4,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "        act_layer=nn.GELU,\n",
    "        Attention_block=FlexibleRoPEAttention,\n",
    "        Mlp_block=Mlp,\n",
    "        init_values=1e-4,\n",
    "    )\n",
    "\n",
    "print(\"=\" * 2 + \"encoder pass\" + \"=\" * 100)\n",
    "x_emb, meta_patches, mask, nr_meta_patches = encoder(x=x, win_size=win_size, mask_ratio=mask_ratio)\n",
    "\n",
    "print(\"=\" * 2 + \"decoder pass\" + \"=\" * 100)\n",
    "x_pred = decoder(x=x_emb, nr_meta_patches=nr_meta_patches, H=H, W=W, win_size=win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "0796c644-25a7-44e4-933c-5f8449b6afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([4, 258, 10])\n",
      "mask.shape: torch.Size([4, 258])\n",
      "x: tensor([[   0,    1,    2,    3,    4,    5,    6,    7,    8,    9],\n",
      "        [  10,   11,   12,   13,   14,   15,   16,   17,   18,   19],\n",
      "        [  30,   31,   32,   33,   34,   35,   36,   37,   38,   39],\n",
      "        [  60,   61,   62,   63,   64,   65,   66,   67,   68,   69],\n",
      "        [ 150,  151,  152,  153,  154,  155,  156,  157,  158,  159],\n",
      "        [ 200,  201,  202,  203,  204,  205,  206,  207,  208,  209],\n",
      "        [ 270,  271,  272,  273,  274,  275,  276,  277,  278,  279],\n",
      "        [ 290,  291,  292,  293,  294,  295,  296,  297,  298,  299],\n",
      "        [ 330,  331,  332,  333,  334,  335,  336,  337,  338,  339],\n",
      "        [ 340,  341,  342,  343,  344,  345,  346,  347,  348,  349],\n",
      "        [ 360,  361,  362,  363,  364,  365,  366,  367,  368,  369],\n",
      "        [ 480,  481,  482,  483,  484,  485,  486,  487,  488,  489],\n",
      "        [ 590,  591,  592,  593,  594,  595,  596,  597,  598,  599],\n",
      "        [ 600,  601,  602,  603,  604,  605,  606,  607,  608,  609],\n",
      "        [ 620,  621,  622,  623,  624,  625,  626,  627,  628,  629],\n",
      "        [ 640,  641,  642,  643,  644,  645,  646,  647,  648,  649],\n",
      "        [ 760,  761,  762,  763,  764,  765,  766,  767,  768,  769],\n",
      "        [ 790,  791,  792,  793,  794,  795,  796,  797,  798,  799],\n",
      "        [ 800,  801,  802,  803,  804,  805,  806,  807,  808,  809],\n",
      "        [ 820,  821,  822,  823,  824,  825,  826,  827,  828,  829],\n",
      "        [ 850,  851,  852,  853,  854,  855,  856,  857,  858,  859],\n",
      "        [ 880,  881,  882,  883,  884,  885,  886,  887,  888,  889],\n",
      "        [ 910,  911,  912,  913,  914,  915,  916,  917,  918,  919],\n",
      "        [ 950,  951,  952,  953,  954,  955,  956,  957,  958,  959],\n",
      "        [ 980,  981,  982,  983,  984,  985,  986,  987,  988,  989],\n",
      "        [1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089],\n",
      "        [1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109],\n",
      "        [1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119],\n",
      "        [1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179],\n",
      "        [1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219],\n",
      "        [1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299],\n",
      "        [1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
      "        [1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339],\n",
      "        [1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359],\n",
      "        [1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369],\n",
      "        [1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389],\n",
      "        [1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409],\n",
      "        [1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439],\n",
      "        [1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509],\n",
      "        [1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549],\n",
      "        [1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579],\n",
      "        [1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719],\n",
      "        [1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759],\n",
      "        [1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769],\n",
      "        [1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779],\n",
      "        [1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789],\n",
      "        [1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869],\n",
      "        [1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909],\n",
      "        [1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919],\n",
      "        [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929],\n",
      "        [1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949],\n",
      "        [1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969],\n",
      "        [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989],\n",
      "        [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019],\n",
      "        [2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049],\n",
      "        [2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139],\n",
      "        [2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149],\n",
      "        [2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179],\n",
      "        [2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209],\n",
      "        [2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239],\n",
      "        [2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339],\n",
      "        [2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399],\n",
      "        [2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489],\n",
      "        [2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499],\n",
      "        [2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519],\n",
      "        [2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559]])\n",
      "ids_rest: tensor([[  0,   0,   0,  ...,   0,   0,   0],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  3,   3,   3,  ...,   3,   3,   3],\n",
      "        ...,\n",
      "        [254, 254, 254,  ..., 254, 254, 254],\n",
      "        [256, 256, 256,  ..., 256, 256, 256],\n",
      "        [257, 257, 257,  ..., 257, 257, 257]])\n",
      "restored x.shape: torch.Size([4, 258, 10])\n",
      "diff: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "B, N, D = 4, 258, 10\n",
    "x = torch.arange(B * N * D).reshape(B, N, D)\n",
    "#print(x[0])\n",
    "x_org = x.clone()\n",
    "\n",
    "mask, ids_restore = random_masking_smart(x, mask_ratio, nr_meta_patches)\n",
    "\n",
    "# == Encoder ==\n",
    "\n",
    "x = x[mask].view(B, -1, D)\n",
    "#print(x[0])\n",
    "#print(\"x_masked.shape:\", x.shape)\n",
    "\n",
    "# == Decoder ==\n",
    "\n",
    "# in the decoder, we need to fill the masked tokens first\n",
    "mask_tokens = x_org[~mask].view(B, -1, D)\n",
    "#mask_token = nn.Parameter(torch.zeros(1, 1, D))\n",
    "#mask_tokens = mask_token.repeat(B, mask.shape[1] + nr_meta_patches - ids_kept.shape[1], 1)\n",
    "x = torch.cat([x, mask_tokens], dim=1)\n",
    "\n",
    "# rearrange\n",
    "x_reordered = torch.zeros_like(x)\n",
    "x = x_reordered.scatter_(1, ids_restore, x)\n",
    "\n",
    "print(\"restored x.shape:\", x.shape)\n",
    "print(\"diff:\", (x - x_org)[mask].view(B, -1, D)[0]) # not zero :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fbf0b-b5f1-4fcc-8109-56657fc42801",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = nn.Parameter(torch.zeros(1, 1, D))\n",
    "mask_tokens_real = mask_token.repeat(B, mask.shape[1] - kept_indices.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "316c2ace-9857-4a52-aed2-8fe6e153599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x:\n",
      "tensor([[[    0,     1,     2,  ...,     7,     8,     9],\n",
      "         [   10,    11,    12,  ...,    17,    18,    19],\n",
      "         [   20,    21,    22,  ...,    27,    28,    29],\n",
      "         ...,\n",
      "         [ 2550,  2551,  2552,  ...,  2557,  2558,  2559],\n",
      "         [ 2560,  2561,  2562,  ...,  2567,  2568,  2569],\n",
      "         [ 2570,  2571,  2572,  ...,  2577,  2578,  2579]],\n",
      "\n",
      "        [[ 2580,  2581,  2582,  ...,  2587,  2588,  2589],\n",
      "         [ 2590,  2591,  2592,  ...,  2597,  2598,  2599],\n",
      "         [ 2600,  2601,  2602,  ...,  2607,  2608,  2609],\n",
      "         ...,\n",
      "         [ 5130,  5131,  5132,  ...,  5137,  5138,  5139],\n",
      "         [ 5140,  5141,  5142,  ...,  5147,  5148,  5149],\n",
      "         [ 5150,  5151,  5152,  ...,  5157,  5158,  5159]],\n",
      "\n",
      "        [[ 5160,  5161,  5162,  ...,  5167,  5168,  5169],\n",
      "         [ 5170,  5171,  5172,  ...,  5177,  5178,  5179],\n",
      "         [ 5180,  5181,  5182,  ...,  5187,  5188,  5189],\n",
      "         ...,\n",
      "         [ 7710,  7711,  7712,  ...,  7717,  7718,  7719],\n",
      "         [ 7720,  7721,  7722,  ...,  7727,  7728,  7729],\n",
      "         [ 7730,  7731,  7732,  ...,  7737,  7738,  7739]],\n",
      "\n",
      "        [[ 7740,  7741,  7742,  ...,  7747,  7748,  7749],\n",
      "         [ 7750,  7751,  7752,  ...,  7757,  7758,  7759],\n",
      "         [ 7760,  7761,  7762,  ...,  7767,  7768,  7769],\n",
      "         ...,\n",
      "         [10290, 10291, 10292,  ..., 10297, 10298, 10299],\n",
      "         [10300, 10301, 10302,  ..., 10307, 10308, 10309],\n",
      "         [10310, 10311, 10312,  ..., 10317, 10318, 10319]]])\n",
      "ids_restore:\n",
      "torch.Size([4, 258])\n",
      "Expanded ids_restore shape: torch.Size([4, 258, 10])\n",
      "Reordered tensor x_reordered:\n",
      "tensor([[[ 2300,  2301,  2302,  ...,  2307,  2308,  2309],\n",
      "         [ 1360,  1361,  1362,  ...,  1367,  1368,  1369],\n",
      "         [ 1570,  1571,  1572,  ...,  1577,  1578,  1579],\n",
      "         ...,\n",
      "         [ 2530,  2531,  2532,  ...,  2537,  2538,  2539],\n",
      "         [ 1830,  1831,  1832,  ...,  1837,  1838,  1839],\n",
      "         [  130,   131,   132,  ...,   137,   138,   139]],\n",
      "\n",
      "        [[ 4880,  4881,  4882,  ...,  4887,  4888,  4889],\n",
      "         [ 3940,  3941,  3942,  ...,  3947,  3948,  3949],\n",
      "         [ 4150,  4151,  4152,  ...,  4157,  4158,  4159],\n",
      "         ...,\n",
      "         [ 5110,  5111,  5112,  ...,  5117,  5118,  5119],\n",
      "         [ 4410,  4411,  4412,  ...,  4417,  4418,  4419],\n",
      "         [ 2710,  2711,  2712,  ...,  2717,  2718,  2719]],\n",
      "\n",
      "        [[ 7460,  7461,  7462,  ...,  7467,  7468,  7469],\n",
      "         [ 6520,  6521,  6522,  ...,  6527,  6528,  6529],\n",
      "         [ 6730,  6731,  6732,  ...,  6737,  6738,  6739],\n",
      "         ...,\n",
      "         [ 7690,  7691,  7692,  ...,  7697,  7698,  7699],\n",
      "         [ 6990,  6991,  6992,  ...,  6997,  6998,  6999],\n",
      "         [ 5290,  5291,  5292,  ...,  5297,  5298,  5299]],\n",
      "\n",
      "        [[10040, 10041, 10042,  ..., 10047, 10048, 10049],\n",
      "         [ 9100,  9101,  9102,  ...,  9107,  9108,  9109],\n",
      "         [ 9310,  9311,  9312,  ...,  9317,  9318,  9319],\n",
      "         ...,\n",
      "         [10270, 10271, 10272,  ..., 10277, 10278, 10279],\n",
      "         [ 9570,  9571,  9572,  ...,  9577,  9578,  9579],\n",
      "         [ 7870,  7871,  7872,  ...,  7877,  7878,  7879]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example setup\n",
    "B, N, D = 4, 258, 10\n",
    "\n",
    "# Create a tensor with a whole number range for easier tracking\n",
    "x = torch.arange(B * N * D).reshape(B, N, D)\n",
    "print(\"Original tensor x:\")\n",
    "print(x)\n",
    "\n",
    "# Example ids_restore (ensuring ids_restore is a valid permutation of indices for each row)\n",
    "ids_restore = torch.randperm(N).repeat(B, 1)\n",
    "print(\"ids_restore:\")\n",
    "print(ids_restore.shape)\n",
    "\n",
    "# Expand ids_restore to match the shape of x\n",
    "ids_restore_expanded = ids_restore.unsqueeze(-1).expand(-1, -1, D)\n",
    "print(\"Expanded ids_restore shape:\", ids_restore_expanded.shape)\n",
    "\n",
    "# Rearrange x according to ids_restore\n",
    "x_reordered = torch.gather(x, dim=1, index=ids_restore_expanded)\n",
    "print(\"Reordered tensor x_reordered:\")\n",
    "print(x_reordered)\n",
    "\n",
    "# Verify that the reordered tensor matches the expected output\n",
    "# (manually verify or write additional checks to confirm correctness)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
