{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Notebook for Thesis (Pretrained Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "Bye world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")\n",
    "\n",
    "# Add custom path\n",
    "import sys\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/\")\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import lightning.pytorch as L\n",
    "import xgboost as xgb\n",
    "import torchaudio\n",
    "from natsort import natsorted\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, confusion_matrix, mean_squared_error, \n",
    "    mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Custom imports\n",
    "from src.data.transforms import crop_spg, normalize_spg\n",
    "from src.models.mae_rope_encoder import EncoderViTRoPE\n",
    "from src.utils.preloading.utils import load_edf_to_dataframe\n",
    "from timm.models.vision_transformer import Mlp\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "\n",
    "# Seed everything\n",
    "L.seed_everything(42)\n",
    "\n",
    "print(\"Bye world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train/Val/Test Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "#Â TUAB and Epilepsy\n",
    "\n",
    "yc_class = {\n",
    "    \"class_name\": \"YC\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation/tueg/edf\",\n",
    "    \"load_mode\": 2,\n",
    "}\n",
    "\n",
    "tuab = {\n",
    "    \"task_name\": \"TUAB\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/tuab_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "epilepsy = {\n",
    "    \"task_name\": \"Epilepsy\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/epilepsy_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "yc_tasks = [tuab, epilepsy]\n",
    "\n",
    "########################################################################################################################\n",
    "# Clinical JSONs\n",
    "\n",
    "cli_class = {\n",
    "    \"class_name\": \"Clinical\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "age = {\n",
    "    \"task_name\": \"Age\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/age2_light.json\",\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "depression = {\n",
    "    \"task_name\": \"Depression\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_depression_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "parkinsons = {\n",
    "    \"task_name\": \"Parkinsons\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/parkinsons2_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "schizophrenia = {\n",
    "    \"task_name\": \"Schizophrenia\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_schizophrenia_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "sex = {\n",
    "    \"task_name\": \"Sex\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/sex2_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "cli_tasks = [age, depression, parkinsons, schizophrenia, sex]\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# Motor-Imagery JSONs\n",
    "\n",
    "mi_class = {\n",
    "    \"class_name\": \"Motor Imagery\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "eye_open_closed = {\n",
    "    \"task_name\": \"EyeOpenClosed\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_open_closed_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"eye open\", \"eye closed\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "eye_vh = {\n",
    "    \"task_name\": \"EyeVH\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_vh_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"vertical\", \"horizontal\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_imaginary = {\n",
    "    \"task_name\": \"FlexionExtensionImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"hand movement imagined elbow flexion\",\n",
    "            \"hand movement imagined elbow extension\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_real = {\n",
    "    \"task_name\": \"FlexionExtensionReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"hand movement elbow extension\", \"hand movement elbow flexion\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_imaginary = {\n",
    "    \"task_name\": \"GraspImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined palmar grasp\", \"imagined lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_real = {\n",
    "    \"task_name\": \"GraspReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement palmar grasp\", \"movement lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "lr_imaginary = {\n",
    "    \"task_name\": \"LRImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"left hand imagined movement\", \"right hand imagined movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "lr_real = {\n",
    "    \"task_name\": \"LRReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"right hand movement\", \"left hand movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_imagined = {\n",
    "    \"task_name\": \"BodyPartsImagined\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_imagined_body_parts_light.json\",\n",
    "    \"out_dim\": 5,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"rest\",\n",
    "            \"right hand imagined movement\",\n",
    "            \"foot imagined movement\",\n",
    "            \"left hand imagined movement\",\n",
    "            \"tongue imagined movement\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_real = {\n",
    "    \"task_name\": \"BodyPartsReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_body_parts_light.json\",\n",
    "    \"out_dim\": 4,\n",
    "    \"outputs\": set(\n",
    "        [\"rest\", \"right hand movement\", \"foot movement\", \"left hand movement\"]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "pronation_supination_imaginary = {\n",
    "    \"task_name\": \"PronationSupinationImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined supination\", \"imagined pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "pronation_supination_real = {\n",
    "    \"task_name\": \"PronationSupinationReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement supination\", \"movement pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "mi_tasks = [eye_open_closed, eye_vh, flexion_extension_imaginary, flexion_extension_real, \n",
    "            grasp_imaginary, grasp_real, lr_imaginary, lr_real,\n",
    "            mi_task_body_parts_imagined, mi_task_body_parts_real,\n",
    "            pronation_supination_imaginary, pronation_supination_real]\n",
    "\n",
    "########################################################################################################################\n",
    "# ERP JSONs\n",
    "\n",
    "erp_class = {\n",
    "    \"class_name\": \"Error-Related Potential\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "erp = {\n",
    "    \"task_name\": \"ERP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/new_erp_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"with event-related potential\",\n",
    "            \"without event-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "errp = {\n",
    "    \"task_name\": \"ERRP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/errp_all_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"without error-related potential\",\n",
    "            \"with error-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "erp_tasks = [erp, errp]\n",
    "\n",
    "########################################################################################################################\n",
    "# EyeNet JSONs\n",
    "\n",
    "eye_class = {\n",
    "    \"class_name\": \"EyeNet\",\n",
    "    \"time_col\": \"time\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_amp = {\n",
    "    \"task_name\": \"EyeNetDirectionAmp\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_ang = {\n",
    "    \"task_name\": \"EyeNetDirectionAng\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_lr = {\n",
    "    \"task_name\": \"EyeNetLR\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_position = {\n",
    "    \"task_name\": \"EyeNetPosition\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_tasks = [eye_dir_amp, eye_dir_ang, eye_lr, eye_position]\n",
    "\n",
    "classes = {\n",
    "    \"YC\": [yc_class, yc_tasks], \n",
    "    \"Clinical\": [cli_class, cli_tasks], \n",
    "    \"MI\": [mi_class, mi_tasks],\n",
    "    \"ERP\": [erp_class, erp_tasks], \n",
    "    \"EyeNet\": [eye_class, eye_tasks],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Load Data into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task channels: {'o1', 'a1', 't6', 'oz', 'cz', 'fp2', 'p3', 'a2', 't5', 'p4', 'f3', 't4', 'f8', 'c4p', 'fz', 'pz', 'c3p', 't3', 't2', 'c4', 't1', 'c3', 'o2', 'f7', 'f4', 'fp1'}\n",
      "Preparing local paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[get_node_index] # Trials = 216556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared local paths. 0 files found on node.\n",
      "==========Load train data====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [00:41<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Load test data=====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 200/200 [00:42<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Channels: {'o1', 'a1', 't6', 'cz', 'fp2', 'p3', 'a2', 't5', 'p4', 'f3', 't4', 'f8', 'fz', 'pz', 't3', 't2', 'c4', 't1', 'c3', 'o2', 'f7', 'f4', 'fp1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Select the class and task\n",
    "\n",
    "used_class = yc_class\n",
    "# used_class = cli_class\n",
    "# used_class = mi_class\n",
    "# used_class = erp_class\n",
    "# used_class = eye_class\n",
    "#\n",
    "used_task = tuab\n",
    "# used_task = epilepsy\n",
    "# used_task = age\n",
    "# used_task = depression\n",
    "# used_task = parkinsons\n",
    "# used_task = schizophrenia\n",
    "# used_task = sex\n",
    "#\n",
    "# used_task = eye_open_closed\n",
    "# used_task = eye_vh\n",
    "# used_task = flexion_extension_imaginary\n",
    "# used_task = flexion_extension_real\n",
    "# used_task = grasp_real\n",
    "# used_task = lr_imaginary\n",
    "# used_task = lr_real\n",
    "# used_task = mi_task_body_parts_real\n",
    "# used_task = mi_task_body_parts_imagined\n",
    "# used_task = pronation_supination_real\n",
    "# used_task = pronation_supination_imaginary\n",
    "#\n",
    "# used_task = erp\n",
    "# used_task = errp\n",
    "#\n",
    "# used_task = eye_dir_amp\n",
    "# used_task = eye_dir_ang\n",
    "# used_task = eye_lr\n",
    "# used_task = eye_position\n",
    "\n",
    "class_name = used_class[\"class_name\"]\n",
    "time_col = used_class[\"time_col\"]\n",
    "prefix_filepath = used_class[\"prefix_filepath\"]\n",
    "load_mode = used_class[\"load_mode\"]\n",
    "task_name = used_task[\"task_name\"]\n",
    "task_type = used_task[\"task_type\"]\n",
    "json_path = used_task[\"json_path\"]\n",
    "out_dim = used_task[\"out_dim\"]\n",
    "short_mode = used_task[\"short_mode\"] if \"short_mode\" in used_task else False\n",
    "\n",
    "truncate = True\n",
    "num_keep = 100\n",
    "\n",
    "with open(f\"/itet-stor/maxihuber/net_scratch/finetune_files/channels/{class_name.replace(' ', '_')}_{task_name}_cleaned.json\", \"r\") as f:\n",
    "    task_channels = set(natsorted(list(json.load(f))))\n",
    "print(f\"Task channels: {task_channels}\")\n",
    "\n",
    "def load_index0(data_index_path):\n",
    "    with open(data_index_path, \"r\") as f:\n",
    "        train_test_dict = json.load(f)\n",
    "    train_samples = train_test_dict[\"train\"]\n",
    "    test_samples = train_test_dict[\"test\"]\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def load_index1(data_index_paths):\n",
    "    all_samples = []\n",
    "    for data_index_path in data_index_paths:\n",
    "        with open(data_index_path, \"r\") as f:\n",
    "            subset_dict = json.load(f)\n",
    "        all_samples.append(list(subset_dict.values())[0])\n",
    "    return all_samples[0], all_samples[1], all_samples[2]\n",
    "\n",
    "def truncate0(train_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, test_index\n",
    "\n",
    "def truncate1(train_index, val_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    val_index = val_index[:num_keep] + val_index[-num_keep:] if truncate else val_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, val_index, test_index\n",
    "\n",
    "def get_node_index(index_patterns):\n",
    "    index_paths = []\n",
    "    for pattern in index_patterns:  # regex the index_patterns\n",
    "        index_paths.extend(glob.glob(pattern))\n",
    "    num_trials = 0\n",
    "    trial_info_index = {}\n",
    "    for index_path in index_paths:\n",
    "        with open(index_path, \"r\") as f:\n",
    "            new_trial_info_index = json.load(f)\n",
    "            for trial_info in new_trial_info_index.values():\n",
    "                trial_info_index[num_trials] = trial_info\n",
    "                num_trials += 1\n",
    "    print(f\"[get_node_index] # Trials = {num_trials}\", file=sys.stderr)\n",
    "    return trial_info_index\n",
    "\n",
    "def get_full_paths(input_files, prefix_filepath, filename_to_nodepath):\n",
    "    adjusted_files = []\n",
    "    for file in input_files:\n",
    "        file_ = os.path.basename(file)\n",
    "        if file_ in filename_to_nodepath:\n",
    "            adjusted_files.append(filename_to_nodepath[file_])\n",
    "        else:\n",
    "            file = prefix_filepath + file if \"/itet-stor\" not in file else file.replace(\"/itet-stor/kard\", \"/itet-stor/maxihuber\")\n",
    "            adjusted_files.append(file)\n",
    "    return adjusted_files\n",
    "\n",
    "def get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "def load_file_data(data_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col):\n",
    "    num_samples = 0\n",
    "    data = {}\n",
    "    outputs = {}\n",
    "    srs = {}\n",
    "    durs = {}\n",
    "    channels = {}\n",
    "    failed_samples = []\n",
    "    all_channels = set(task_channels)\n",
    "\n",
    "    for sample in tqdm(data_index, desc=\"Loading data\", position=0, leave=True):\n",
    "        try:\n",
    "            input_files = get_full_paths(sample[\"input\"], prefix_filepath, filename_to_nodepath)\n",
    "\n",
    "            if load_mode == 2:\n",
    "                file = input_files[0]\n",
    "                df = load_edf_to_dataframe(file)\n",
    "            else:\n",
    "                dataframes = [pd.read_pickle(file) for file in input_files]\n",
    "                df = pd.concat(dataframes, axis=0)\n",
    "            \n",
    "            start = int(sample[\"start\"])\n",
    "            length = int(sample[\"length\"]) if \"length\" in sample else int(sample[\"end\"])\n",
    "            df = df.loc[start : start + length, :] if load_mode == 1 else df.iloc[start:length, :]\n",
    "            assert len(df) > 0, f\"Empty dataframe for sample: {sample}\"\n",
    "\n",
    "            if load_mode != 1:\n",
    "                outputs[num_samples] = sample.get(\"output\", sample.get(\"label\"))\n",
    "            else:\n",
    "                outputs[num_samples] = list(sample[\"output\"].values()) if task_name == \"EyeNetPosition\" else list(sample[\"output\"].values())[0]\n",
    "            \n",
    "            sr = int(1 / (df[time_col].iloc[1] - df[time_col].iloc[0]))\n",
    "            srs[num_samples] = sr\n",
    "            durs[num_samples] = len(df) / sr\n",
    "\n",
    "            df.columns = [get_generic_channel_name(col) for col in df.columns]\n",
    "\n",
    "            valid_channels = set(df.columns) & set(task_channels)\n",
    "            all_channels &= valid_channels  # Intersect with previously seen channels\n",
    "            channels[num_samples] = sorted(valid_channels, key=lambda x: list(task_channels).index(x))\n",
    "            df = df[channels[num_samples]].astype(float)\n",
    "            data[num_samples] = torch.tensor(df.to_numpy(), dtype=torch.float32).T\n",
    "            \n",
    "            num_samples += 1\n",
    "            \n",
    "            del df\n",
    "            if num_samples % 100 == 0:\n",
    "                gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process sample: {sample}. Error: {e}\", file=sys.stderr)\n",
    "            failed_samples.append(sample)\n",
    "\n",
    "    return data, outputs, srs, durs, channels, all_channels\n",
    "\n",
    "\n",
    "print(f\"Preparing local paths...\")\n",
    "index_patterns = [\"/dev/shm/mae/index_*.json\", \"/scratch/mae/index_*.json\"]\n",
    "node_index = get_node_index(index_patterns=index_patterns)\n",
    "filename_to_nodepath = {os.path.basename(ie[\"origin_path\"]): ie[\"new_path\"] for trial_idx, ie in node_index.items()}\n",
    "filename_to_nodepath = {}\n",
    "print(f\"Prepared local paths. {len(filename_to_nodepath)} files found on node.\")\n",
    "\n",
    "#Â TODO: parallelize\n",
    "if load_mode != 1:\n",
    "    train_index, test_index = load_index0(json_path)\n",
    "    train_index, test_index = truncate0(train_index, test_index, num_keep, truncate)\n",
    "    \n",
    "    print(\"=\" * 10 + \"Load train data\" + \"=\" * 100)\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_all_channels = (\n",
    "        load_file_data(train_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load test data\" + \"=\" * 101)\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_all_channels = (\n",
    "        load_file_data(test_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\n",
    "    )\n",
    "    common_channels = train_all_channels & test_all_channels\n",
    "    assert len(common_channels) > 0, \"No common channel found across samples!\"\n",
    "    print(f\"Common Channels: {common_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win size: 8\n"
     ]
    }
   ],
   "source": [
    "class FinetuneDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        outputs,\n",
    "        srs,\n",
    "        durs,\n",
    "        channels,\n",
    "        task_type,\n",
    "        label_encoder=None,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.outputs = outputs\n",
    "        self.srs = srs\n",
    "        self.durs = durs\n",
    "        self.channels = channels\n",
    "        self.task_type = task_type\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals = self.data[idx]\n",
    "        output = self.outputs[idx]\n",
    "        sr = self.srs[idx]\n",
    "        dur = self.durs[idx]\n",
    "        channels = self.channels[idx]\n",
    "\n",
    "        if self.task_type == \"Classification\" and self.label_encoder is not None:\n",
    "            output = self.label_encoder.transform([output])[0]\n",
    "            output_tensor = torch.tensor(output, dtype=torch.long)\n",
    "        else:\n",
    "            if task_name == \"EyeNetPosition\":\n",
    "                output_tensor = torch.tensor(output, dtype=torch.float32)\n",
    "            else:\n",
    "                output_tensor = torch.tensor([output], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"signals\": signals,\n",
    "            \"output\": output_tensor,\n",
    "            \"sr\": sr,\n",
    "            \"dur\": dur,\n",
    "            \"channels\": channels,\n",
    "        }\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "def get_nr_y_patches(win_size, sr, self_patch_size):\n",
    "    return int((sr / 2 * win_size + 1) / self_patch_size)\n",
    "\n",
    "\n",
    "def get_nr_x_patches(win_size, dur, self_win_shift_factor, self_patch_size):\n",
    "    win_shift = win_size * self_win_shift_factor\n",
    "    x_datapoints_per_second = 1 / win_shift\n",
    "    x_datapoints = dur * x_datapoints_per_second + 1\n",
    "    return int(x_datapoints // self_patch_size)\n",
    "\n",
    "# DataLoaders\n",
    "self_win_shifts = [2, 4, 8]\n",
    "self_patch_size = 16\n",
    "self_win_shift_factor = 0.25\n",
    "self_max_win_shift = self_win_shifts[-1]\n",
    "self_max_y_datapoints = 4_000\n",
    "self_max_nr_patches = 6_000\n",
    "\n",
    "srs = list(train_sr.values()) + list(test_sr.values())\n",
    "durs = list(train_dur.values()) + list(test_dur.values())\n",
    "valid_win_shifts = [\n",
    "    win_shift\n",
    "    for win_shift in self_win_shifts\n",
    "    for sr, dur in zip(srs, durs)\n",
    "    if get_nr_y_patches(win_shift, sr, self_patch_size) >= 1\n",
    "    and get_nr_x_patches(win_shift, dur, self_win_shift_factor, self_patch_size) >= 1\n",
    "]\n",
    "assert len(valid_win_shifts) > 0, \"No valid win_shifts found!\"\n",
    "win_size = valid_win_shifts[-1] # largest possible win_shift\n",
    "print(f\"Win size: {win_size}\")\n",
    "\n",
    "def self_get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "\n",
    "def self_encode_mean(mean, win_size, self_max_y_datapoints, self_max_win_shift):\n",
    "    y_datapoints = mean.shape[0]\n",
    "    encoded_mean = torch.zeros(self_max_y_datapoints)\n",
    "    step_size = int(self_max_win_shift // win_size)\n",
    "    end_idx = step_size * y_datapoints\n",
    "    indices = torch.arange(0, end_idx, step_size)\n",
    "    encoded_mean[indices] = mean.squeeze_().float()\n",
    "    encoded_mean.unsqueeze_(1)\n",
    "    return encoded_mean\n",
    "\n",
    "def get_max_dur(n_chns, win_size, sr, self_win_shift_factor, self_patch_size, self_max_nr_patches):\n",
    "    single_channel_max_dur = int(\n",
    "        (\n",
    "            (self_patch_size**2) * self_max_nr_patches\n",
    "            - sr * win_size / 2\n",
    "            - 1\n",
    "        )\n",
    "        / (\n",
    "            sr / self_win_shift_factor / 2\n",
    "            + 1 / self_win_shift_factor / win_size\n",
    "        )\n",
    "    )\n",
    "    max_dur = int(single_channel_max_dur / n_chns)\n",
    "    return max_dur\n",
    "\n",
    "def sample_collate_fn(batch, self_channel_name_map, win_size, self_patch_size, self_win_shift_factor, self_max_nr_patches):\n",
    "\n",
    "    signals, output, sr, dur, channels = (\n",
    "        batch[0][\"signals\"],\n",
    "        batch[0][\"output\"],\n",
    "        batch[0][\"sr\"],\n",
    "        batch[0][\"dur\"],\n",
    "        batch[0][\"channels\"],\n",
    "    )\n",
    "\n",
    "    # truncate signals along time axis to stay below cuda memory limit\n",
    "    max_dur = get_max_dur(len(channels), win_size, sr, self_win_shift_factor, self_patch_size, self_max_nr_patches)\n",
    "    if dur > max_dur:\n",
    "        dur = max_dur\n",
    "        signals = signals[:, :int(sr * dur)]\n",
    "\n",
    "    fft = torchaudio.transforms.Spectrogram(\n",
    "        n_fft=int(sr * win_size),\n",
    "        win_length=int(sr * win_size),\n",
    "        hop_length=int(sr * win_size * self_win_shift_factor),\n",
    "        normalized=True,\n",
    "    )\n",
    "\n",
    "    spg_list = []\n",
    "    chn_list = []\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "\n",
    "    for signal, channel in zip(signals, channels):\n",
    "\n",
    "        # Channel information\n",
    "        channel_name = self_get_generic_channel_name(channel)\n",
    "        channel = (\n",
    "            self_channel_name_map[channel_name]\n",
    "            if channel_name in self_channel_name_map\n",
    "            else self_channel_name_map[\"None\"]\n",
    "        )\n",
    "\n",
    "        # Spectrogram Computation & Cropping\n",
    "        spg = fft(signal)\n",
    "        spg = spg**2\n",
    "        spg = crop_spg(spg, self_patch_size)\n",
    "\n",
    "        H_new, W_new = spg.shape[0], spg.shape[1]\n",
    "        h_new, w_new = H_new // self_patch_size, W_new // self_patch_size\n",
    "\n",
    "        # Prepare channel information (per-patch)\n",
    "        channel = torch.full((h_new, w_new), channel, dtype=torch.float16)\n",
    "\n",
    "        spg, mean, std = normalize_spg(spg)\n",
    "        mean = self_encode_mean(mean, win_size, self_max_y_datapoints, self_max_win_shift)\n",
    "        std = self_encode_mean(std, win_size, self_max_y_datapoints, self_max_win_shift)\n",
    "\n",
    "        spg_list.append(spg)\n",
    "        chn_list.append(channel)\n",
    "        mean_list.append(mean)\n",
    "        std_list.append(std)\n",
    "\n",
    "    batch = torch.stack(spg_list)\n",
    "    channels_encoded = torch.stack(chn_list)\n",
    "    means = torch.stack(mean_list)\n",
    "    stds = torch.stack(std_list)\n",
    "\n",
    "    batch.unsqueeze_(1)\n",
    "    channels_encoded = channels_encoded.flatten(1)\n",
    "    means = means.transpose(1, 2)\n",
    "    stds = stds.transpose(1, 2)\n",
    "\n",
    "    full_batch = {\n",
    "        \"batch\": batch,\n",
    "        \"channels\": channels_encoded,\n",
    "        \"means\": means,\n",
    "        \"stds\": stds,\n",
    "        \"win_size\": win_size,\n",
    "        \"channels_raw\": channels,\n",
    "    }\n",
    "\n",
    "    # == Finished iterating over all possible window shifts\n",
    "\n",
    "    return full_batch, output\n",
    "\n",
    "def move_to_device(obj, device):\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj.to(device)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: move_to_device(value, device) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [move_to_device(item, device) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(move_to_device(item, device) for item in obj)\n",
    "    # Add other types as necessary (e.g., sets)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 170 | Val: 30 | Test: 200\n"
     ]
    }
   ],
   "source": [
    "#Â Mapping of channel names to IDs\n",
    "channel_name_map_path = \"/home/maxihuber/eeg-foundation/src/data/components/channels_to_id3.json\"\n",
    "with open(channel_name_map_path, \"r\") as f:\n",
    "    self_channel_name_map = json.load(f)\n",
    "\n",
    "# Label encoder\n",
    "all_outputs = list(set(list(train_outputs.values()) + list(test_outputs.values())))\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_outputs)\n",
    "\n",
    "full_train_dataset = FinetuneDataset(\n",
    "    train_data,\n",
    "    train_outputs,\n",
    "    train_sr,\n",
    "    train_dur,\n",
    "    train_channels,\n",
    "    task_type=task_type,\n",
    "    label_encoder=label_encoder,\n",
    ")\n",
    "test_dataset = FinetuneDataset(\n",
    "    test_data,\n",
    "    test_outputs,\n",
    "    test_sr,\n",
    "    test_dur,\n",
    "    test_channels,\n",
    "    task_type=task_type,\n",
    "    label_encoder=label_encoder,\n",
    ")\n",
    "# Define the split ratio\n",
    "train_ratio = 0.85\n",
    "val_ratio = 0.15\n",
    "\n",
    "# Calculate lengths for train and validation sets\n",
    "total_size = len(full_train_dataset)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create a partially applied function\n",
    "partial_collate_fn = partial(\n",
    "    sample_collate_fn, \n",
    "    self_channel_name_map=self_channel_name_map, \n",
    "    win_size=win_size, \n",
    "    self_patch_size=self_patch_size, \n",
    "    self_win_shift_factor=self_win_shift_factor, \n",
    "    self_max_nr_patches=self_max_nr_patches,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=partial_collate_fn, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=partial_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=partial_collate_fn)\n",
    "\n",
    "print(f\"Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuningModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        frozen_encoder,\n",
    "        out_dim,\n",
    "        task_name,\n",
    "        task_type,\n",
    "        learning_rate,\n",
    "        mask_ratio,\n",
    "    ):\n",
    "        super(FineTuningModel, self).__init__()\n",
    "\n",
    "        self.task_name = task_name\n",
    "        self.task_type = task_type\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "        # Pretrained network\n",
    "        self.encoder = encoder\n",
    "        if frozen_encoder:\n",
    "            self.freeze_encoder()\n",
    "\n",
    "        self.head = nn.Linear(encoder.encoder_embed_dim, out_dim)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        spgs = x[\"batch\"]\n",
    "        channels = x[\"channels\"]\n",
    "        means = x[\"means\"]\n",
    "        stds = x[\"stds\"]\n",
    "        win_size = x[\"win_size\"]\n",
    "\n",
    "        x_emb, _, _, _, _ = self.encoder(\n",
    "            x=spgs,\n",
    "            means=means,\n",
    "            stds=stds,\n",
    "            channels=channels,\n",
    "            win_size=win_size,\n",
    "            mask_ratio=self.mask_ratio,\n",
    "        )\n",
    "        \n",
    "        del spgs, channels, means, stds\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Get CLS tokens\n",
    "        x_emb = x_emb[:, 0, :]\n",
    "\n",
    "        # Could be done better\n",
    "        x_emb_allcls = x_emb\n",
    "        x_emb = torch.mean(x_emb, dim=0)\n",
    "\n",
    "        return x_emb, x_emb_allcls, x[\"channels_raw\"]\n",
    "\n",
    "    def freeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "chkpt_path = \"/itet-stor/maxihuber/net_scratch/checkpoints/1004189/manual-epoch-end.ckpt\"\n",
    "checkpoint = torch.load(chkpt_path, map_location=torch.device(\"cpu\"))\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "state_dict = {\n",
    "    k.replace(\"net.encoder.\", \"\"): v\n",
    "    for k, v in state_dict.items()\n",
    "    if \"net.encoder.\" in k\n",
    "}\n",
    "\n",
    "# Initialize the encoder and load the state dict\n",
    "encoder = EncoderViTRoPE(\n",
    "    channel_names_path=channel_name_map_path,\n",
    "    mask_ratio=0.0,\n",
    "    encoder_embed_dim=768,\n",
    "    encoder_depth=12,\n",
    "    encoder_num_heads=12,\n",
    "    encoder_mlp_ratio=4,\n",
    "    encoder_qkv_bias=True,\n",
    "    encoder_drop_rate=0.1,\n",
    "    encoder_attn_drop_rate=0.1,\n",
    "    encoder_drop_path_rate=0.1,\n",
    "    encoder_init_scale=1e-4,\n",
    "    encoder_rope_theta=100.0,\n",
    ")\n",
    "encoder.load_state_dict(state_dict)\n",
    "\n",
    "# Check if GPU is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Instantiate the fine-tuning model\n",
    "fine_tuning_model = FineTuningModel(\n",
    "    encoder=encoder,\n",
    "    frozen_encoder=True,\n",
    "    out_dim=out_dim,\n",
    "    task_name=task_name,\n",
    "    task_type=task_type,\n",
    "    learning_rate=0.01,\n",
    "    mask_ratio=0,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define the function to extract embeddings\n",
    "def extract_embeddings(loader):\n",
    "    embeddings = []\n",
    "    embeddings_allcls = []\n",
    "    labels = []\n",
    "    embeddings_channels = []  # List to store channel names for each batch\n",
    "    for i, (full_batch, label) in tqdm(enumerate(loader), desc=\"Extracting encoder embeddings\", position=0, leave=True):\n",
    "        full_batch = move_to_device(full_batch, device)  # Move inputs to the GPU\n",
    "        with torch.no_grad():  # No need to compute gradients for inference\n",
    "            x_emb, x_emb_allcls, x_channels = fine_tuning_model(full_batch)\n",
    "        embeddings.append(x_emb.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "        embeddings_allcls.append(x_emb_allcls.cpu().numpy())\n",
    "        labels.append(label.cpu().numpy())\n",
    "        embeddings_channels.append(x_channels)  # Append the channel names\n",
    "        # Delete tensors to free GPU memory\n",
    "        del full_batch, label, x_emb, x_emb_allcls\n",
    "        torch.cuda.empty_cache()\n",
    "        if i % 100 == 0:\n",
    "            gc.collect()\n",
    "    embeddings = np.vstack(embeddings)  # shape (n_samples, encoder_embed_dim)\n",
    "    labels = np.array(labels)\n",
    "    return embeddings, labels, embeddings_allcls, embeddings_channels\n",
    "\n",
    "finetune_models = {\n",
    "    \"Classification\": {\n",
    "        \"XGBoost\": xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"XGBoost\": xgb.XGBRegressor(objective='reg:squarederror', use_label_encoder=False, eval_metric='rmse', random_state=42)\n",
    "    },\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    \"Classification\": {\n",
    "        \"Accuracy\": accuracy_score,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "        \"Precision\": partial(precision_score, zero_division=np.nan),\n",
    "        \"Recall\": partial(recall_score, zero_division=np.nan),\n",
    "        \"F1 Score\": partial(f1_score, zero_division=np.nan),\n",
    "        \"ROC AUC\": roc_auc_score,\n",
    "        \"Confusion Matrix\": confusion_matrix,\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"MAE\": mean_absolute_error,\n",
    "        \"RMSE\": lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False),  # Using lambda for RMSE\n",
    "        \"R-squared\": r2_score,\n",
    "        \"MAPE\": mean_absolute_percentage_error,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting encoder embeddings: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting encoder embeddings: 170it [00:47,  3.60it/s]\n",
      "Extracting encoder embeddings: 200it [00:55,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored train embeddings at /itet-stor/maxihuber/net_scratch/finetune_embeddings/YC/TUAB/test_data_2024-06-28_23-47\n",
      "Stored train embeddings at /itet-stor/maxihuber/net_scratch/finetune_scores/YC/TUAB/test_data_2024-06-28-21:22\n",
      "Training set class distribution: Counter({0: 86, 1: 84})\n",
      "Test set class distribution: Counter({1: 112, 0: 88})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==========XGBoost Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored scores at /itet-stor/maxihuber/net_scratch/finetune_scores/YC/TUAB/model_scores_2024-06-28_23-47.csv\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "models_dir = f'/itet-stor/maxihuber/net_scratch/finetune_models/{class_name}/{task_name}'\n",
    "scores_dir = f'/itet-stor/maxihuber/net_scratch/finetune_scores/{class_name}/{task_name}'\n",
    "embeds_dir = f'/itet-stor/maxihuber/net_scratch/finetune_embeddings/{class_name}/{task_name}'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(scores_dir, exist_ok=True)\n",
    "os.makedirs(embeds_dir, exist_ok=True)\n",
    "\n",
    "# Step 7: Extract embeddings for training data\n",
    "train_embeddings, y_train, train_embeddings_allcls, train_channels = extract_embeddings(train_loader)\n",
    "\n",
    "# Step 8: Extract embeddings for test data\n",
    "test_embeddings, y_test, test_embeddings_allcls, test_channels = extract_embeddings(test_loader)\n",
    "\n",
    "# Step 9: Store the embeddings to a file\n",
    "train_data_tuple = (train_embeddings, y_train, train_embeddings_allcls, train_channels)\n",
    "train_data_path = os.path.join(embeds_dir, f'train_data_{timestamp}')\n",
    "test_data_tuple = (test_embeddings, y_test, test_embeddings_allcls, test_channels)\n",
    "train_data_path = os.path.join(embeds_dir, f'test_data_{timestamp}')\n",
    "with open(train_data_path, 'wb') as f:\n",
    "    pickle.dump(train_data_tuple, f)\n",
    "    print(f\"Stored train embeddings at {train_data_path}\")\n",
    "with open(test_data_path, 'wb') as f:\n",
    "    pickle.dump(test_data_tuple, f)\n",
    "    print(f\"Stored train embeddings at {test_data_path}\")\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Training set class distribution:\", Counter(y_train))\n",
    "print(\"Test set class distribution:\", Counter(y_test))\n",
    "\n",
    "# Initialize a list to store the scores\n",
    "scores_list = []\n",
    "\n",
    "for name, clf in finetune_models[task_type].items():\n",
    "    print(\"=\" * 10 + f\"{name} Model\" + \"=\" * 100, file=sys.stderr)\n",
    "    \n",
    "    if name == \"XGBoost\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(train_embeddings)\n",
    "        X_test_scaled = scaler.transform(test_embeddings)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "    else:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(train_embeddings, y_train)\n",
    "        y_pred = clf.predict(test_embeddings)\n",
    "\n",
    "    # Store the fitted predictor for later use\n",
    "    if name == \"XGBoost\":\n",
    "        model_path = os.path.join(models_dir, f\"{name}_model_{timestamp}.json\")\n",
    "        clf.save_model(model_path)\n",
    "    else:\n",
    "        model_path = os.path.join(models_dir, f\"{name}_model_{timestamp}.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(clf, f)\n",
    "\n",
    "    model_scores = {'Model': name}\n",
    "    for score_name, score_func in scores[task_type].items():\n",
    "        score = score_func(y_test, y_pred)\n",
    "        model_scores[score_name] = score\n",
    "\n",
    "    # Store the scores for later use\n",
    "    scores_list.append(model_scores)\n",
    "\n",
    "    # Clean up to save memory\n",
    "    del clf, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "# Convert the scores list to a DataFrame and save it\n",
    "scores_df = pd.DataFrame(scores_list)\n",
    "scores_path = os.path.join(scores_dir, f\"model_scores_{timestamp}.csv\")\n",
    "scores_df.to_csv(scores_path, index=False)\n",
    "print(f\"Stored scores at {scores_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
