{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9b1a80-cd86-4ed3-b427-f038f1e0601a",
   "metadata": {},
   "source": [
    "# Finetuning Notebook for Thesis (Simple Classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f2d7d-b21d-4383-ac28-f6f3616c10aa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec7e8af-477d-4d7a-b00d-4c6a7da090ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "Bye world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")\n",
    "\n",
    "# Add custom path\n",
    "import sys\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/\")\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import lightning.pytorch as L\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, mean_squared_error, mean_absolute_error,\n",
    "    r2_score, mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.preprocessing import Xdawn\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Custom imports\n",
    "from src.utils.preloading.utils import load_edf_to_dataframe\n",
    "\n",
    "# Seed everything\n",
    "L.seed_everything(42)\n",
    "\n",
    "print(\"Bye world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea036b9-4979-4883-8acc-708017b99fb1",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428f8de-eb21-492f-b8fd-a274c9a8d86a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Define Train/Val/Test Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140a137e-6e06-483e-8ff6-f9722725fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# TUAB and Epilepsy\n",
    "\n",
    "yc_class = {\n",
    "    \"class_name\": \"YC\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation/tueg/edf\",\n",
    "    \"load_mode\": 2,\n",
    "}\n",
    "\n",
    "tuab = {\n",
    "    \"task_name\": \"TUAB\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/tuab_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "epilepsy = {\n",
    "    \"task_name\": \"Epilepsy\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/epilepsy_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "yc_tasks = [tuab, epilepsy]\n",
    "\n",
    "########################################################################################################################\n",
    "# Clinical JSONs\n",
    "\n",
    "cli_class = {\n",
    "    \"class_name\": \"Clinical\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "age = {\n",
    "    \"task_name\": \"Age\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/age_light.json\",\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "depression = {\n",
    "    \"task_name\": \"Depression\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_depression_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "parkinsons = {\n",
    "    \"task_name\": \"Parkinsons\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_parkinsons_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "schizophrenia = {\n",
    "    \"task_name\": \"Schizophrenia\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_schizophrenia_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "sex = {\n",
    "    \"task_name\": \"Sex\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/sex_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "cli_tasks = [age, depression, parkinsons, schizophrenia, sex]\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# Motor-Imagery JSONs\n",
    "\n",
    "mi_class = {\n",
    "    \"class_name\": \"Motor Imagery\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "eye_open_closed = {\n",
    "    \"task_name\": \"EyeOpenClosed\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_open_closed_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"eye open\", \"eye closed\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "eye_vh = {\n",
    "    \"task_name\": \"EyeVH\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_vh_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"vertical\", \"horizontal\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_imaginary = {\n",
    "    \"task_name\": \"FlexionExtensionImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"hand movement imagined elbow flexion\",\n",
    "            \"hand movement imagined elbow extension\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_real = {\n",
    "    \"task_name\": \"FlexionExtensionReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"hand movement elbow extension\", \"hand movement elbow flexion\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_imaginary = {\n",
    "    \"task_name\": \"GraspImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined palmar grasp\", \"imagined lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_real = {\n",
    "    \"task_name\": \"GraspReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement palmar grasp\", \"movement lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "lr_imaginary = {\n",
    "    \"task_name\": \"LRImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"left hand imagined movement\", \"right hand imagined movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "lr_real = {\n",
    "    \"task_name\": \"LRReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"right hand movement\", \"left hand movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_imagined = {\n",
    "    \"task_name\": \"BodyPartsImagined\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_imagined_body_parts_light.json\",\n",
    "    \"out_dim\": 5,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"rest\",\n",
    "            \"right hand imagined movement\",\n",
    "            \"foot imagined movement\",\n",
    "            \"left hand imagined movement\",\n",
    "            \"tongue imagined movement\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_real = {\n",
    "    \"task_name\": \"BodyPartsReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_body_parts_light.json\",\n",
    "    \"out_dim\": 4,\n",
    "    \"outputs\": set(\n",
    "        [\"rest\", \"right hand movement\", \"foot movement\", \"left hand movement\"]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "pronation_supination_imaginary = {\n",
    "    \"task_name\": \"PronationSupinationImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined supination\", \"imagined pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "pronation_supination_real = {\n",
    "    \"task_name\": \"PronationSupinationReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement supination\", \"movement pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "mi_tasks = [eye_open_closed, eye_vh, flexion_extension_imaginary, flexion_extension_real, \n",
    "            grasp_imaginary, grasp_real, lr_imaginary, lr_real,\n",
    "            mi_task_body_parts_imagined, mi_task_body_parts_real,\n",
    "            pronation_supination_imaginary, pronation_supination_real]\n",
    "\n",
    "########################################################################################################################\n",
    "# ERP JSONs\n",
    "\n",
    "erp_class = {\n",
    "    \"class_name\": \"Error-Related Potential\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "erp = {\n",
    "    \"task_name\": \"ERP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/new_erp_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"with event-related potential\",\n",
    "            \"without event-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "errp = {\n",
    "    \"task_name\": \"ERRP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/errp_all_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"without error-related potential\",\n",
    "            \"with error-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "erp_tasks = [erp, errp]\n",
    "\n",
    "########################################################################################################################\n",
    "# EyeNet JSONs\n",
    "\n",
    "eye_class = {\n",
    "    \"class_name\": \"EyeNet\",\n",
    "    \"time_col\": \"time\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_amp = {\n",
    "    \"task_name\": \"EyeNetDirectionAmp\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_ang = {\n",
    "    \"task_name\": \"EyeNetDirectionAng\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_lr = {\n",
    "    \"task_name\": \"EyeNetLR\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_position = {\n",
    "    \"task_name\": \"EyeNetPosition\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_tasks = [eye_dir_amp, eye_dir_ang, eye_lr, eye_position]\n",
    "\n",
    "classes = {\n",
    "    \"YC\": [yc_class, yc_tasks], \n",
    "    \"Clinical\": [cli_class, cli_tasks], \n",
    "    \"MI\": [mi_class, mi_tasks],\n",
    "    \"ERP\": [erp_class, erp_tasks], \n",
    "    \"EyeNet\": [eye_class, eye_tasks],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b6468-0350-4044-99ba-3683577cd59b",
   "metadata": {},
   "source": [
    "### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2ba553-0c71-4133-9175-500d9b25fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task channels: {'t5', 'o2', 'p3', 't6', 'pz', 'o1', 'f7', 't4', 't1', 'fp1', 'f3', 'oz', 'f4', 'p4', 't2', 'c4', 'fp2', 'cz', 'fz', 'f8', 'c3', 't3'}\n",
      "Preparing local paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[get_node_index] # Trials = 216556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared local paths. 214804 files found on node.\n",
      "==========Load train data====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:59<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Load test data=====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:12<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Channels: {'cz'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Select the class and task\n",
    "\n",
    "# used_class = yc_class\n",
    "# used_class = cli_class\n",
    "used_class = mi_class\n",
    "# used_class = erp_class\n",
    "# used_class = eye_class\n",
    "#\n",
    "# used_task = tuab\n",
    "# used_task = epilepsy\n",
    "# used_task = age\n",
    "# used_task = depression\n",
    "# used_task = parkinsons\n",
    "# used_task = schizophrenia\n",
    "# used_task = sex\n",
    "#\n",
    "used_task = eye_open_closed\n",
    "# used_task = eye_vh\n",
    "# used_task = flexion_extension_imaginary\n",
    "# used_task = flexion_extension_real\n",
    "# used_task = grasp_real\n",
    "# used_task = lr_imaginary\n",
    "# used_task = lr_real\n",
    "# used_task = mi_task_body_parts_real\n",
    "# used_task = mi_task_body_parts_imagined\n",
    "# used_task = pronation_supination_real\n",
    "# used_task = pronation_supination_imaginary\n",
    "#\n",
    "# used_task = erp\n",
    "# used_task = errp\n",
    "#\n",
    "# used_task = eye_dir_amp\n",
    "# used_task = eye_dir_ang\n",
    "# used_task = eye_lr\n",
    "# used_task = eye_position\n",
    "\n",
    "class_name = used_class[\"class_name\"]\n",
    "time_col = used_class[\"time_col\"]\n",
    "prefix_filepath = used_class[\"prefix_filepath\"]\n",
    "load_mode = used_class[\"load_mode\"]\n",
    "task_name = used_task[\"task_name\"]\n",
    "task_type = used_task[\"task_type\"]\n",
    "json_path = used_task[\"json_path\"]\n",
    "out_dim = used_task[\"out_dim\"]\n",
    "short_mode = used_task[\"short_mode\"] if \"short_mode\" in used_task else False\n",
    "\n",
    "with open('/home/maxihuber/eeg-foundation/src/data/components/channels_to_id3.json', 'r') as f:\n",
    "    chn_to_id = json.load(f)\n",
    "    task_channels = set([chn for chn, id in chn_to_id.items() if id > 0]) # excludes \"None\"\n",
    "print(f\"Task channels: {task_channels}\")\n",
    "\n",
    "truncate = False\n",
    "num_keep = 100\n",
    "\n",
    "def load_index0(data_index_path):\n",
    "    with open(data_index_path, \"r\") as f:\n",
    "        train_test_dict = json.load(f)\n",
    "    train_samples = train_test_dict[\"train\"]\n",
    "    test_samples = train_test_dict[\"test\"]\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def load_index1(data_index_paths):\n",
    "    all_samples = []\n",
    "    for data_index_path in data_index_paths:\n",
    "        with open(data_index_path, \"r\") as f:\n",
    "            subset_dict = json.load(f)\n",
    "        all_samples.append(list(subset_dict.values())[0])\n",
    "    return all_samples[0], all_samples[1], all_samples[2]\n",
    "\n",
    "def truncate0(train_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, test_index\n",
    "\n",
    "def truncate1(train_index, val_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    val_index = val_index[:num_keep] + val_index[-num_keep:] if truncate else val_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, val_index, test_index\n",
    "\n",
    "def get_node_index(index_patterns):\n",
    "    index_paths = []\n",
    "    for pattern in index_patterns:  # regex the index_patterns\n",
    "        index_paths.extend(glob.glob(pattern))\n",
    "    num_trials = 0\n",
    "    trial_info_index = {}\n",
    "    for index_path in index_paths:\n",
    "        with open(index_path, \"r\") as f:\n",
    "            new_trial_info_index = json.load(f)\n",
    "            for trial_info in new_trial_info_index.values():\n",
    "                trial_info_index[num_trials] = trial_info\n",
    "                num_trials += 1\n",
    "    print(f\"[get_node_index] # Trials = {num_trials}\", file=sys.stderr)\n",
    "    return trial_info_index\n",
    "\n",
    "def get_full_paths(input_files, prefix_filepath, filename_to_nodepath):\n",
    "    adjusted_files = []\n",
    "    for file in input_files:\n",
    "        file = os.path.basename(file)\n",
    "        if file in filename_to_nodepath:\n",
    "            adjusted_files.append(filename_to_nodepath[file])\n",
    "        else:\n",
    "            file = prefix_filepath + file if \"/itet-stor\" not in file else file.replace(\"/itet-stor/kard\", \"/itet-stor/maxihuber\")\n",
    "            adjusted_files.append(file)\n",
    "    return adjusted_files\n",
    "\n",
    "def get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "def load_file_data(data_index, task_channels, filename_to_nodepath, load_mode, task_name):\n",
    "    num_samples = 0\n",
    "    data = {}\n",
    "    outputs = {}\n",
    "    srs = {}\n",
    "    durs = {}\n",
    "    channels = {}\n",
    "    failed_samples = []\n",
    "    all_channels = set(task_channels)\n",
    "\n",
    "    for sample in tqdm(data_index, desc=\"Loading data\", position=0, leave=True):\n",
    "        try:\n",
    "            input_files = get_full_paths(sample[\"input\"], prefix_filepath, filename_to_nodepath)\n",
    "\n",
    "            if load_mode == 2:\n",
    "                file = input_files[0]\n",
    "                df = load_edf_to_dataframe(file)\n",
    "            else:\n",
    "                dataframes = [pd.read_pickle(file) for file in input_files]\n",
    "                df = pd.concat(dataframes, axis=0)\n",
    "            \n",
    "            start = int(sample[\"start\"])\n",
    "            length = int(sample[\"length\"]) if \"length\" in sample else int(sample[\"end\"])\n",
    "            df = df.loc[start : start + length, :] if load_mode == 1 else df.iloc[start:length, :]\n",
    "            assert len(df) > 0, f\"Empty dataframe for sample: {sample}\"\n",
    "\n",
    "            if load_mode != 1:\n",
    "                outputs[num_samples] = sample.get(\"output\", sample.get(\"label\"))\n",
    "            else:\n",
    "                outputs[num_samples] = list(sample[\"output\"].values()) if task_name == \"EyeNetPosition\" else list(sample[\"output\"].values())[0]\n",
    "            \n",
    "            sr = int(1 / (df[\"time in seconds\"].iloc[1] - df[\"time in seconds\"].iloc[0]))\n",
    "            srs[num_samples] = sr\n",
    "            durs[num_samples] = len(df) / sr\n",
    "\n",
    "            df.columns = [get_generic_channel_name(col) for col in df.columns]\n",
    "\n",
    "            valid_channels = set(df.columns) & set(task_channels)\n",
    "            all_channels &= valid_channels  # Intersect with previously seen channels\n",
    "            channels[num_samples] = sorted(valid_channels, key=lambda x: list(task_channels).index(x))\n",
    "            df = df[channels[num_samples]].astype(float)\n",
    "            data[num_samples] = torch.tensor(df.to_numpy(), dtype=torch.float32).T\n",
    "            \n",
    "            num_samples += 1\n",
    "            \n",
    "            del df\n",
    "            if num_samples % 100 == 0:\n",
    "                gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process sample: {sample}. Error: {e}\", file=sys.stderr)\n",
    "            failed_samples.append(sample)\n",
    "\n",
    "    return data, outputs, srs, durs, channels, all_channels\n",
    "\n",
    "\n",
    "print(f\"Preparing local paths...\")\n",
    "index_patterns = [\"/dev/shm/mae/index_*.json\", \"/scratch/mae/index_*.json\"]\n",
    "node_index = get_node_index(index_patterns=index_patterns)\n",
    "filename_to_nodepath = {os.path.basename(ie[\"origin_path\"]): ie[\"new_path\"] for trial_idx, ie in node_index.items()}\n",
    "print(f\"Prepared local paths. {len(filename_to_nodepath)} files found on node.\")\n",
    "\n",
    "if load_mode != 1:\n",
    "    train_index, test_index = load_index0(json_path)\n",
    "    train_index, test_index = truncate0(train_index, test_index, num_keep, truncate)\n",
    "    \n",
    "    print(\"=\" * 10 + \"Load train data\" + \"=\" * 100)\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_all_channels = (\n",
    "        load_file_data(train_index, task_channels, filename_to_nodepath, load_mode, task_name)\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load test data\" + \"=\" * 101)\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_all_channels = (\n",
    "        load_file_data(test_index, task_channels, filename_to_nodepath, load_mode, task_name)\n",
    "    )\n",
    "    common_channels = train_all_channels & test_all_channels\n",
    "    print(f\"Common Channels: {common_channels}\")\n",
    "\n",
    "else:\n",
    "    train_index, val_index, test_index = load_index1(json_path)\n",
    "    train_index, val_index, test_index = truncate1(train_index, val_index, test_index, num_keep, truncate)\n",
    "    \n",
    "    print(\"=\" * 10 + \"Load train data\" + \"=\" * 100)\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_all_channels = (\n",
    "        load_file_data(train_index, task_channels, filename_to_nodepath, load_mode, task_name)\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load val data\" + \"=\" * 102)\n",
    "    val_data, val_outputs, val_sr, val_dur, val_channels, val_all_channels = load_file_data(\n",
    "        val_index, task_channels, filename_to_nodepath, load_mode, task_name\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load test data\" + \"=\" * 101)\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_all_channels = (\n",
    "        load_file_data(test_index, task_channels, filename_to_nodepath, load_mode, task_name)\n",
    "    )\n",
    "    common_channels = train_all_channels & val_all_channels & test_all_channels\n",
    "    print(f\"Common Channels: {common_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7502a-6b61-4828-bf1c-e7b8f5cddc66",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f65a6-9ecf-4f1a-89cd-7ac4d06c8757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc108915",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a4ad85-e544-4be1-8061-a1dd64d985c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor, target_height, target_width):\n",
    "    current_height, current_width = tensor.shape\n",
    "\n",
    "    if current_height < target_height:\n",
    "        padding_height = target_height - current_height\n",
    "        padding = torch.zeros((padding_height, current_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=0)\n",
    "    else:\n",
    "        tensor = tensor[:target_height, :]\n",
    "\n",
    "    if current_width < target_width:\n",
    "        padding_width = target_width - current_width\n",
    "        padding = torch.zeros((tensor.shape[0], padding_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=1)\n",
    "    else:\n",
    "        tensor = tensor[:, :target_width]\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def resample_signals(data, srs, target_sfreq):\n",
    "    resampled_data = {}\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Resampling signals\"):\n",
    "        signal_numpy = signal.numpy().astype(np.float64)\n",
    "        signal_resampled = mne.filter.resample(signal_numpy, up=target_sfreq / srs[idx])\n",
    "        resampled_data[idx] = torch.tensor(signal_resampled, dtype=torch.float32)\n",
    "        del signal_numpy, signal_resampled  # Free memory\n",
    "        if idx % 100 == 0:\n",
    "            gc.collect()\n",
    "    return resampled_data\n",
    "\n",
    "def pad_or_truncate_signals(data, common_length):\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Pad/Truncate signals\"):\n",
    "        signal_length = signal.shape[1]\n",
    "        if signal_length < common_length:\n",
    "            pad_width = common_length - signal_length\n",
    "            signal_padded = np.pad(signal, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        else:\n",
    "            signal_padded = signal[:, :common_length]\n",
    "        data[idx] = torch.tensor(signal_padded, dtype=torch.float32)\n",
    "        del signal, signal_padded  # Free memory\n",
    "        if idx % 100 == 0:\n",
    "            gc.collect()\n",
    "    return data\n",
    "\n",
    "def create_epochs(data, outputs, channels, sfreq=1000, is_classification=True):\n",
    "    events = []\n",
    "    event_id = {}\n",
    "    epochs_data = []\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Creating epochs\"):\n",
    "        epochs_data.append(signal.numpy())\n",
    "        if is_classification:\n",
    "            if outputs[idx] not in event_id:\n",
    "                event_id[outputs[idx]] = len(event_id) + 1\n",
    "            events.append([idx, 0, event_id[outputs[idx]]])\n",
    "        else:\n",
    "            events.append([idx, 0, 1])\n",
    "    events = np.array(events, dtype=int)\n",
    "    info = mne.create_info(\n",
    "        ch_names=channels, sfreq=sfreq, ch_types=\"eeg\"\n",
    "    )\n",
    "    epochs = mne.EpochsArray(\n",
    "        np.array(epochs_data),\n",
    "        info,\n",
    "        events=events,\n",
    "        event_id=event_id if is_classification else None,\n",
    "    )\n",
    "    del events, info, epochs_data  # Free memory\n",
    "    gc.collect()  # Explicitly invoke garbage collection\n",
    "    return epochs\n",
    "\n",
    "def pad_data(data, target_height, target_width):\n",
    "    padded_data = {}\n",
    "    for k, signals in tqdm(data.items(), desc=\"Padding data\"):\n",
    "        padded_data[k] = pad_tensor(signals, target_height, target_width)\n",
    "    return padded_data\n",
    "\n",
    "def filter_channels_by_indices(data, channels, common_channels):\n",
    "    filtered_data = {}\n",
    "    for k, signals in tqdm(data.items(), desc=\"Collect common channels\"):\n",
    "        common_channel_indices = [i for i, ch in enumerate(channels[k]) if ch in common_channels]\n",
    "        filtered_data[k] = signals[common_channel_indices, :]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387a9b7-5b7a-45ad-9f9e-4136aa5f3541",
   "metadata": {},
   "source": [
    "### Applying xDAWN Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87ea15d2-0db4-448e-b1dc-90e0206b4184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect common channels: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:00<00:00, 22757.91it/s]\n",
      "Collect common channels: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 22148.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sampling Frequency: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling signals: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:03<00:00, 124.11it/s]\n",
      "Resampling signals: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 91.58it/s]\n",
      "Pad/Truncate signals:   0%|▍                                                                                                                                                                                                         | 1/442 [00:00<04:06,  1.79it/s]/tmp/ipykernel_1927658/1523345857.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[idx] = torch.tensor(signal_padded, dtype=torch.float32)\n",
      "Pad/Truncate signals: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:02<00:00, 152.13it/s]\n",
      "Pad/Truncate signals: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 120.60it/s]\n",
      "Creating epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:00<00:00, 257269.27it/s]\n",
      "Creating epochs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 192964.78it/s]\n",
      "Start fitting Xdawn...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xdawn({'correct_overlap': False, 'n_components': 2, 'reg': 0.1, 'signal_cov': None})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/src/models/components/Baselines\")\n",
    "\n",
    "# Filter data by common channels\n",
    "train_data_filtered = filter_channels_by_indices(train_data, train_channels, common_channels)\n",
    "test_data_filtered = filter_channels_by_indices(test_data, test_channels, common_channels)\n",
    "\n",
    "# Resample signals\n",
    "target_sfreq = int(max(list(train_sr.values()) + list(test_sr.values())))\n",
    "print(f\"Target Sampling Frequency: {target_sfreq}\")\n",
    "\n",
    "train_data_resampled = resample_signals(train_data_filtered, train_sr, target_sfreq)\n",
    "test_data_resampled = resample_signals(test_data_filtered, test_sr, target_sfreq)\n",
    "del train_data_filtered, test_data_filtered  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "# Get duration and channel counts for padding/truncating\n",
    "durs = [signals_tensor.shape[1] for idx, signals_tensor in train_data_resampled.items()] + [signals_tensor.shape[1] for idx, signals_tensor in test_data_resampled.items()]\n",
    "dur_90 = int(np.percentile(durs, 90))\n",
    "common_length = dur_90\n",
    "\n",
    "# Pad and truncate signals\n",
    "train_data_padded = pad_or_truncate_signals(train_data_resampled, common_length)\n",
    "test_data_padded = pad_or_truncate_signals(test_data_resampled, common_length)\n",
    "del train_data_resampled, test_data_resampled  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "is_classification = True if task_type == \"Classification\" else False\n",
    "epochs_train = create_epochs(\n",
    "    train_data_padded, train_outputs, list(common_channels), target_sfreq, is_classification\n",
    ")\n",
    "epochs_test = create_epochs( \n",
    "    test_data_padded, test_outputs, list(common_channels), target_sfreq, is_classification\n",
    ")\n",
    "del train_data_padded, test_data_padded  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "print(\"Start fitting Xdawn...\", file=sys.stderr)\n",
    "\n",
    "xdawn = Xdawn(n_components=2, correct_overlap=False, reg=0.1)\n",
    "xdawn.fit(epochs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778e0ab-d9b2-444e-8f8a-ebd4b2ff8ceb",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e08dd",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b9cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(train_outputs, test_outputs, is_classification):\n",
    "    if is_classification:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = label_encoder.fit_transform(list(train_outputs.values()))\n",
    "        y_test = label_encoder.transform(list(test_outputs.values()))\n",
    "    else:\n",
    "        y_train = np.array(list(train_outputs.values()))\n",
    "        y_test = np.array(list(test_outputs.values()))\n",
    "    return y_train, y_test\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "simple_models = {\n",
    "    \"Classification\": {\n",
    "        \"LDA\": LinearDiscriminantAnalysis(),\n",
    "        \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "        \"Linear SVM\": SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "        \"RBF SVM\": SVC(gamma=2, C=1, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "        ),\n",
    "        \"AdaBoost\": AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge Regression\": Ridge(alpha=1.0, random_state=42),\n",
    "        \"K-Nearest Neighbors Regressor\": KNeighborsRegressor(n_neighbors=3),\n",
    "        \"Support Vector Regression (Linear)\": SVR(kernel='linear', C=1.0),\n",
    "        \"Support Vector Regression (RBF)\": SVR(kernel='rbf', C=1.0, gamma=0.1),\n",
    "        \"Decision Tree Regressor\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "        \"Random Forest Regressor\": RandomForestRegressor(\n",
    "            max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "        ),\n",
    "        \"AdaBoost Regressor\": AdaBoostRegressor(n_estimators=50, random_state=42),\n",
    "    },\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    \"Classification\": {\n",
    "        \"Accuracy\": accuracy_score,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "        \"Precision\": partial(precision_score, zero_division=np.nan),\n",
    "        \"Recall\": partial(recall_score, zero_division=np.nan),\n",
    "        \"F1 Score\": partial(f1_score, zero_division=np.nan),\n",
    "        \"ROC AUC\": roc_auc_score,\n",
    "        \"Confusion Matrix\": confusion_matrix,\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"MAE\": mean_absolute_error,\n",
    "        \"RMSE\": lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False),  # Using lambda for RMSE\n",
    "        \"R-squared\": r2_score,\n",
    "        \"MAPE\": mean_absolute_percentage_error,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adaa5fd",
   "metadata": {},
   "source": [
    "### Actual Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e10e692-f09f-499a-bcef-a74abba07cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution: Counter({0: 293, 1: 149})\n",
      "Test set class distribution: Counter({1: 36, 0: 36})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==========LDA Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model LDA at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/LDA_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5694444444444444 (LDA)\n",
      "Balanced Accuracy: 0.5694444444444444 (LDA)\n",
      "Precision: 0.7272727272727273 (LDA)\n",
      "Recall: 0.2222222222222222 (LDA)\n",
      "F1 Score: 0.3404255319148936 (LDA)\n",
      "ROC AUC: 0.5694444444444445 (LDA)\n",
      "Confusion Matrix: [[33  3]\n",
      " [28  8]] (LDA)\n",
      "==========QDA Model====================================================================================================\n",
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model QDA at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/QDA_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7916666666666666 (QDA)\n",
      "Balanced Accuracy: 0.7916666666666667 (QDA)\n",
      "Precision: 0.7560975609756098 (QDA)\n",
      "Recall: 0.8611111111111112 (QDA)\n",
      "F1 Score: 0.8051948051948052 (QDA)\n",
      "ROC AUC: 0.7916666666666667 (QDA)\n",
      "Confusion Matrix: [[26 10]\n",
      " [ 5 31]] (QDA)\n",
      "==========Nearest Neighbors Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model Nearest Neighbors at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/Nearest Neighbors_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5694444444444444 (Nearest Neighbors)\n",
      "Balanced Accuracy: 0.5694444444444444 (Nearest Neighbors)\n",
      "Precision: 0.6470588235294118 (Nearest Neighbors)\n",
      "Recall: 0.3055555555555556 (Nearest Neighbors)\n",
      "F1 Score: 0.41509433962264153 (Nearest Neighbors)\n",
      "ROC AUC: 0.5694444444444444 (Nearest Neighbors)\n",
      "Confusion Matrix: [[30  6]\n",
      " [25 11]] (Nearest Neighbors)\n",
      "==========Linear SVM Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model Linear SVM at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/Linear SVM_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5 (Linear SVM)\n",
      "Balanced Accuracy: 0.5 (Linear SVM)\n",
      "Precision: nan (Linear SVM)\n",
      "Recall: 0.0 (Linear SVM)\n",
      "F1 Score: 0.0 (Linear SVM)\n",
      "ROC AUC: 0.5 (Linear SVM)\n",
      "Confusion Matrix: [[36  0]\n",
      " [36  0]] (Linear SVM)\n",
      "==========RBF SVM Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model RBF SVM at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/RBF SVM_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5138888888888888 (RBF SVM)\n",
      "Balanced Accuracy: 0.5138888888888888 (RBF SVM)\n",
      "Precision: 0.6666666666666666 (RBF SVM)\n",
      "Recall: 0.05555555555555555 (RBF SVM)\n",
      "F1 Score: 0.10256410256410256 (RBF SVM)\n",
      "ROC AUC: 0.5138888888888888 (RBF SVM)\n",
      "Confusion Matrix: [[35  1]\n",
      " [34  2]] (RBF SVM)\n",
      "==========Decision Tree Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model Decision Tree at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/Decision Tree_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5555555555555556 (Decision Tree)\n",
      "Balanced Accuracy: 0.5555555555555556 (Decision Tree)\n",
      "Precision: 0.5909090909090909 (Decision Tree)\n",
      "Recall: 0.3611111111111111 (Decision Tree)\n",
      "F1 Score: 0.4482758620689655 (Decision Tree)\n",
      "ROC AUC: 0.5555555555555556 (Decision Tree)\n",
      "Confusion Matrix: [[27  9]\n",
      " [23 13]] (Decision Tree)\n",
      "==========Random Forest Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model Random Forest at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/Random Forest_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4861111111111111 (Random Forest)\n",
      "Balanced Accuracy: 0.4861111111111111 (Random Forest)\n",
      "Precision: 0.4782608695652174 (Random Forest)\n",
      "Recall: 0.3055555555555556 (Random Forest)\n",
      "F1 Score: 0.3728813559322034 (Random Forest)\n",
      "ROC AUC: 0.48611111111111116 (Random Forest)\n",
      "Confusion Matrix: [[24 12]\n",
      " [25 11]] (Random Forest)\n",
      "==========AdaBoost Model====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored model AdaBoost at /itet-stor/maxihuber/net_scratch/finetune_models/Motor Imagery/EyeOpenClosed/AdaBoost_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4722222222222222 (AdaBoost)\n",
      "Balanced Accuracy: 0.4722222222222222 (AdaBoost)\n",
      "Precision: 0.4583333333333333 (AdaBoost)\n",
      "Recall: 0.3055555555555556 (AdaBoost)\n",
      "F1 Score: 0.36666666666666664 (AdaBoost)\n",
      "ROC AUC: 0.4722222222222222 (AdaBoost)\n",
      "Confusion Matrix: [[23 13]\n",
      " [25 11]] (AdaBoost)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored scores at /itet-stor/maxihuber/net_scratch/finetune_scores/Motor Imagery/EyeOpenClosed/model_scores.csv\n"
     ]
    }
   ],
   "source": [
    "models_dir = f'/itet-stor/maxihuber/net_scratch/finetune_models/{class_name}/{task_name}'\n",
    "scores_dir = f'/itet-stor/maxihuber/net_scratch/finetune_scores/{class_name}/{task_name}'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(scores_dir, exist_ok=True)\n",
    "\n",
    "# Transform the data using xDAWN\n",
    "X_train_xdawn = xdawn.transform(epochs_train)\n",
    "X_test_xdawn = xdawn.transform(epochs_test)\n",
    "\n",
    "# Flatten the transformed data for LDA input\n",
    "n_epochs_train, n_components, n_times = X_train_xdawn.shape\n",
    "X_train_xdawn = X_train_xdawn.reshape(n_epochs_train, n_components * n_times)\n",
    "n_epochs_test, n_components, n_times = X_test_xdawn.shape\n",
    "X_test_xdawn = X_test_xdawn.reshape(n_epochs_test, n_components * n_times)\n",
    "\n",
    "y_train, y_test = get_labels(train_outputs, test_outputs, is_classification)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Training set class distribution:\", Counter(y_train))\n",
    "print(\"Test set class distribution:\", Counter(y_test))\n",
    "\n",
    "# Initialize a list to store the scores\n",
    "scores_list = []\n",
    "\n",
    "for name, clf in simple_models[task_type].items():\n",
    "    print(\"=\" * 10 + f\"{name} Model\" + \"=\" * 100, file=sys.stderr)\n",
    "    \n",
    "    clf_pipeline = make_pipeline(StandardScaler(), clf)\n",
    "    clf_pipeline.fit(X_train_xdawn, y_train)\n",
    "\n",
    "    # Store the fitted predictor for later use\n",
    "    model_path = os.path.join(models_dir, f\"{name}_model.pkl\")\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(clf_pipeline, f)\n",
    "    print(f\"Stored model {name} at {model_path}\")\n",
    "\n",
    "    y_pred = clf_pipeline.predict(X_test_xdawn)\n",
    "\n",
    "    model_scores = {'Model': name}\n",
    "    for score_name, score_func in scores[task_type].items():\n",
    "        score = score_func(y_test, y_pred)\n",
    "        model_scores[score_name] = score\n",
    "        print(f\"{score_name}: {score} ({name})\", file=sys.stderr)\n",
    "\n",
    "    # Store the scores for later use\n",
    "    scores_list.append(model_scores)\n",
    "\n",
    "    # Clean up to save memory\n",
    "    del clf_pipeline, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "# Convert the scores list to a DataFrame and save it\n",
    "scores_df = pd.DataFrame(scores_list)\n",
    "scores_path = os.path.join(scores_dir, \"model_scores.csv\")\n",
    "scores_df.to_csv(scores_path, index=False)\n",
    "print(f\"Stored scores at {scores_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dba74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
