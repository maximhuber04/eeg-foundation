{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9b1a80-cd86-4ed3-b427-f038f1e0601a",
   "metadata": {},
   "source": [
    "# Finetuning Notebook for Thesis (Simple Classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f2d7d-b21d-4383-ac28-f6f3616c10aa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec7e8af-477d-4d7a-b00d-4c6a7da090ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")\n",
    "\n",
    "# Add custom path\n",
    "import sys\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/\")\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# Third-party library imports\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import lightning.pytorch as L\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, mean_squared_error, mean_absolute_error,\n",
    "    r2_score, mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "# MNE imports\n",
    "import mne\n",
    "from mne.preprocessing import Xdawn\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Custom imports\n",
    "from src.utils.preloading.utils import load_edf_to_dataframe\n",
    "\n",
    "# Seed everything\n",
    "L.seed_everything(42)\n",
    "\n",
    "print(\"Bye world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea036b9-4979-4883-8acc-708017b99fb1",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428f8de-eb21-492f-b8fd-a274c9a8d86a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Define Train/Val/Test Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140a137e-6e06-483e-8ff6-f9722725fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# TUAB and Epilepsy\n",
    "\n",
    "yc_class = {\n",
    "    \"class_name\": \"YC\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation/tueg/edf\",\n",
    "    \"load_mode\": 2,\n",
    "}\n",
    "\n",
    "tuab = {\n",
    "    \"task_name\": \"TUAB\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/tuab_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "epilepsy = {\n",
    "    \"task_name\": \"Epilepsy\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/epilepsy_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "yc_tasks = [tuab, epilepsy]\n",
    "\n",
    "########################################################################################################################\n",
    "# Clinical JSONs\n",
    "\n",
    "cli_class = {\n",
    "    \"class_name\": \"Clinical\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "age = {\n",
    "    \"task_name\": \"Age\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/age2_light.json\",\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "depression = {\n",
    "    \"task_name\": \"Depression\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_depression_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "parkinsons = {\n",
    "    \"task_name\": \"Parkinsons\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/parkinsons2_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "schizophrenia = {\n",
    "    \"task_name\": \"Schizophrenia\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/cli_schizophrenia_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "sex = {\n",
    "    \"task_name\": \"Sex\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/sex2_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "cli_tasks = [age, depression, parkinsons, schizophrenia, sex]\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# Motor-Imagery JSONs\n",
    "\n",
    "mi_class = {\n",
    "    \"class_name\": \"Motor Imagery\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "eye_open_closed = {\n",
    "    \"task_name\": \"EyeOpenClosed\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_open_closed_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"eye open\", \"eye closed\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "eye_vh = {\n",
    "    \"task_name\": \"EyeVH\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/eye_vh_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"vertical\", \"horizontal\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_imaginary = {\n",
    "    \"task_name\": \"FlexionExtensionImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"hand movement imagined elbow flexion\",\n",
    "            \"hand movement imagined elbow extension\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_real = {\n",
    "    \"task_name\": \"FlexionExtensionReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/flexion_extension_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"hand movement elbow extension\", \"hand movement elbow flexion\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_imaginary = {\n",
    "    \"task_name\": \"GraspImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined palmar grasp\", \"imagined lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_real = {\n",
    "    \"task_name\": \"GraspReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/grasp_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement palmar grasp\", \"movement lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "lr_imaginary = {\n",
    "    \"task_name\": \"LRImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"left hand imagined movement\", \"right hand imagined movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "lr_real = {\n",
    "    \"task_name\": \"LRReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/lr_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"right hand movement\", \"left hand movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_imagined = {\n",
    "    \"task_name\": \"BodyPartsImagined\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_imagined_body_parts_light.json\",\n",
    "    \"out_dim\": 5,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"rest\",\n",
    "            \"right hand imagined movement\",\n",
    "            \"foot imagined movement\",\n",
    "            \"left hand imagined movement\",\n",
    "            \"tongue imagined movement\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_real = {\n",
    "    \"task_name\": \"BodyPartsReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/mi_task_body_parts_light.json\",\n",
    "    \"out_dim\": 4,\n",
    "    \"outputs\": set(\n",
    "        [\"rest\", \"right hand movement\", \"foot movement\", \"left hand movement\"]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "pronation_supination_imaginary = {\n",
    "    \"task_name\": \"PronationSupinationImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_imaginary_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined supination\", \"imagined pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "pronation_supination_real = {\n",
    "    \"task_name\": \"PronationSupinationReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/pronation_supination_real_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement supination\", \"movement pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "mi_tasks = [eye_open_closed, eye_vh, flexion_extension_imaginary, flexion_extension_real, \n",
    "            grasp_imaginary, grasp_real, lr_imaginary, lr_real,\n",
    "            mi_task_body_parts_imagined, mi_task_body_parts_real,\n",
    "            pronation_supination_imaginary, pronation_supination_real]\n",
    "\n",
    "########################################################################################################################\n",
    "# ERP JSONs\n",
    "\n",
    "erp_class = {\n",
    "    \"class_name\": \"Error-Related Potential\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "erp = {\n",
    "    \"task_name\": \"ERP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/new_erp_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"with event-related potential\",\n",
    "            \"without event-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "errp = {\n",
    "    \"task_name\": \"ERRP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/net_scratch/finetune_files/errp_all_light.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"without error-related potential\",\n",
    "            \"with error-related potential\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "erp_tasks = [erp, errp]\n",
    "\n",
    "########################################################################################################################\n",
    "# EyeNet JSONs\n",
    "\n",
    "eye_class = {\n",
    "    \"class_name\": \"EyeNet\",\n",
    "    \"time_col\": \"time\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_amp = {\n",
    "    \"task_name\": \"EyeNetDirectionAmp\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_ang = {\n",
    "    \"task_name\": \"EyeNetDirectionAng\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_lr = {\n",
    "    \"task_name\": \"EyeNetLR\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_position = {\n",
    "    \"task_name\": \"EyeNetPosition\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_tasks = [eye_dir_amp, eye_dir_ang, eye_lr, eye_position]\n",
    "\n",
    "classes = {\n",
    "    \"YC\": [yc_class, yc_tasks], \n",
    "    \"Clinical\": [cli_class, cli_tasks], \n",
    "    \"MI\": [mi_class, mi_tasks],\n",
    "    \"ERP\": [erp_class, erp_tasks], \n",
    "    \"EyeNet\": [eye_class, eye_tasks],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b6468-0350-4044-99ba-3683577cd59b",
   "metadata": {},
   "source": [
    "### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2ba553-0c71-4133-9175-500d9b25fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task channels: {'po4', 'c3', 'f1', 'p4', 'fcz', 'ft7', 'f2', 't8', 'c5', 'af3', 'fc3', 'p8', 'cp5', 'po5', 'po6', 'cz', 'cp2', 'fc2', 'c2', 'c6', 'cpz', 'cp3', 'o1', 'f3', 'cp1', 'f5', 'f6', 'f8', 'po8', 't7', 'tp7', 'tp8', 'ft8', 'p7', 'fp2', 'c1', 'pz', 'cp4', 'fc4', 'fc1', 'fp1', 'f7', 'po3', 'af4', 'fc6', 'fpz', 'p5', 'poz', 'o2', 'po7', 'p6', 'p3', 'f4', 'c4', 'p1', 'fc5', 'fz', 'oz', 'p2', 'cp6'}\n",
      "Preparing local paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[get_node_index] # Trials = 216556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared local paths. 0 files found on node.\n",
      "==========Load train data====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   0%|▊                                                                                                                                                             | 1/200 [00:21<1:12:07, 21.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 189\u001b[0m\n\u001b[1;32m    185\u001b[0m train_index, test_index \u001b[38;5;241m=\u001b[39m truncate0(train_index, test_index, num_keep, truncate)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad train data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    188\u001b[0m train_data, train_outputs, train_sr, train_dur, train_channels, train_all_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mload_file_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_to_nodepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad test data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m101\u001b[39m)\n\u001b[1;32m    192\u001b[0m test_data, test_outputs, test_sr, test_dur, test_channels, test_all_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    193\u001b[0m     load_file_data(test_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\n\u001b[1;32m    194\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 138\u001b[0m, in \u001b[0;36mload_file_data\u001b[0;34m(data_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     dataframes \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_pickle(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m input_files]\n\u001b[0;32m--> 138\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    141\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/internals/concat.py:166\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    163\u001b[0m unit \u001b[38;5;241m=\u001b[39m join_units[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    164\u001b[0m blk \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mblock\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_uniform_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    167\u001b[0m     vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/internals/concat.py:597\u001b[0m, in \u001b[0;36m_is_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# exclude cases where a) ju.block is None or b) we have e.g. Int64+int64\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(first) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# e.g. DatetimeLikeBlock can be dt64 or td64, but these are not uniform\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    588\u001b[0m         ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m first\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;66;03m# GH#42092 we only want the dtype_equal check for non-numeric blocks\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m#  (for now, may change but that would need a deprecation)\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_na\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_extension\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m )\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/internals/concat.py:597\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# exclude cases where a) ju.block is None or b) we have e.g. Int64+int64\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(first) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# e.g. DatetimeLikeBlock can be dt64 or td64, but these are not uniform\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    588\u001b[0m         ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m first\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;66;03m# GH#42092 we only want the dtype_equal check for non-numeric blocks\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m#  (for now, may change but that would need a deprecation)\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_na\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mis_extension \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    598\u001b[0m )\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/internals/concat.py:395\u001b[0m, in \u001b[0;36mJoinUnit.is_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_can_hold_na\u001b[49m:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    398\u001b[0m values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/pandas/core/internals/blocks.py:236\u001b[0m, in \u001b[0;36mBlock._can_hold_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_can_hold_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Can we store NA values in this Block?\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Select the class and task\n",
    "\n",
    "# used_class = yc_class\n",
    "used_class = cli_class\n",
    "# used_class = mi_class\n",
    "# used_class = erp_class\n",
    "# used_class = eye_class\n",
    "#\n",
    "# used_task = tuab\n",
    "# used_task = epilepsy\n",
    "# used_task = age\n",
    "used_task = depression\n",
    "# used_task = parkinsons\n",
    "# used_task = schizophrenia\n",
    "# used_task = sex\n",
    "#\n",
    "# used_task = eye_open_closed\n",
    "# used_task = eye_vh\n",
    "# used_task = flexion_extension_imaginary\n",
    "# used_task = flexion_extension_real\n",
    "# used_task = grasp_real\n",
    "# used_task = lr_imaginary\n",
    "# used_task = lr_real\n",
    "# used_task = mi_task_body_parts_real\n",
    "# used_task = mi_task_body_parts_imagined\n",
    "# used_task = pronation_supination_real\n",
    "# used_task = pronation_supination_imaginary\n",
    "#\n",
    "# used_task = erp\n",
    "# used_task = errp\n",
    "#\n",
    "# used_task = eye_dir_amp\n",
    "# used_task = eye_dir_ang\n",
    "# used_task = eye_lr\n",
    "# used_task = eye_position\n",
    "\n",
    "class_name = used_class[\"class_name\"]\n",
    "time_col = used_class[\"time_col\"]\n",
    "prefix_filepath = used_class[\"prefix_filepath\"]\n",
    "load_mode = used_class[\"load_mode\"]\n",
    "task_name = used_task[\"task_name\"]\n",
    "task_type = used_task[\"task_type\"]\n",
    "json_path = used_task[\"json_path\"]\n",
    "out_dim = used_task[\"out_dim\"]\n",
    "short_mode = used_task[\"short_mode\"] if \"short_mode\" in used_task else False\n",
    "\n",
    "truncate = True\n",
    "num_keep = 100\n",
    "\n",
    "with open(f\"/itet-stor/maxihuber/net_scratch/finetune_files/channels/{class_name.replace(' ', '_')}_{task_name}_cleaned.json\", \"r\") as f:\n",
    "    task_channels = set(natsorted(list(json.load(f))))\n",
    "print(f\"Task channels: {task_channels}\")\n",
    "\n",
    "def load_index0(data_index_path):\n",
    "    with open(data_index_path, \"r\") as f:\n",
    "        train_test_dict = json.load(f)\n",
    "    train_samples = train_test_dict[\"train\"]\n",
    "    test_samples = train_test_dict[\"test\"]\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def load_index1(data_index_paths):\n",
    "    all_samples = []\n",
    "    for data_index_path in data_index_paths:\n",
    "        with open(data_index_path, \"r\") as f:\n",
    "            subset_dict = json.load(f)\n",
    "        all_samples.append(list(subset_dict.values())[0])\n",
    "    return all_samples[0], all_samples[1], all_samples[2]\n",
    "\n",
    "def truncate0(train_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, test_index\n",
    "\n",
    "def truncate1(train_index, val_index, test_index, num_keep, truncate=False):\n",
    "    train_index = train_index[:num_keep] + train_index[-num_keep:] if truncate else train_index\n",
    "    val_index = val_index[:num_keep] + val_index[-num_keep:] if truncate else val_index\n",
    "    test_index = test_index[:num_keep] + test_index[-num_keep:] if truncate else test_index\n",
    "    return train_index, val_index, test_index\n",
    "\n",
    "def get_node_index(index_patterns):\n",
    "    index_paths = []\n",
    "    for pattern in index_patterns:  # regex the index_patterns\n",
    "        index_paths.extend(glob.glob(pattern))\n",
    "    num_trials = 0\n",
    "    trial_info_index = {}\n",
    "    for index_path in index_paths:\n",
    "        with open(index_path, \"r\") as f:\n",
    "            new_trial_info_index = json.load(f)\n",
    "            for trial_info in new_trial_info_index.values():\n",
    "                trial_info_index[num_trials] = trial_info\n",
    "                num_trials += 1\n",
    "    print(f\"[get_node_index] # Trials = {num_trials}\", file=sys.stderr)\n",
    "    return trial_info_index\n",
    "\n",
    "def get_full_paths(input_files, prefix_filepath, filename_to_nodepath):\n",
    "    adjusted_files = []\n",
    "    for file in input_files:\n",
    "        file_ = os.path.basename(file)\n",
    "        if file_ in filename_to_nodepath:\n",
    "            adjusted_files.append(filename_to_nodepath[file_])\n",
    "        else:\n",
    "            file = prefix_filepath + file if \"/itet-stor\" not in file else file.replace(\"/itet-stor/kard\", \"/itet-stor/maxihuber\")\n",
    "            adjusted_files.append(file)\n",
    "    return adjusted_files\n",
    "\n",
    "def get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "def load_file_data(data_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col):\n",
    "    num_samples = 0\n",
    "    data = {}\n",
    "    outputs = {}\n",
    "    srs = {}\n",
    "    durs = {}\n",
    "    channels = {}\n",
    "    failed_samples = []\n",
    "    all_channels = set(task_channels)\n",
    "\n",
    "    for sample in tqdm(data_index, desc=\"Loading data\", position=0, leave=True):\n",
    "        try:\n",
    "            input_files = get_full_paths(sample[\"input\"], prefix_filepath, filename_to_nodepath)\n",
    "\n",
    "            if load_mode == 2:\n",
    "                file = input_files[0]\n",
    "                df = load_edf_to_dataframe(file)\n",
    "            else:\n",
    "                dataframes = [pd.read_pickle(file) for file in input_files]\n",
    "                df = pd.concat(dataframes, axis=0)\n",
    "            \n",
    "            start = int(sample[\"start\"])\n",
    "            length = int(sample[\"length\"]) if \"length\" in sample else int(sample[\"end\"])\n",
    "            df = df.loc[start : start + length, :] if load_mode == 1 else df.iloc[start:length, :]\n",
    "            assert len(df) > 0, f\"Empty dataframe for sample: {sample}\"\n",
    "\n",
    "            if load_mode != 1:\n",
    "                outputs[num_samples] = sample.get(\"output\", sample.get(\"label\"))\n",
    "            else:\n",
    "                outputs[num_samples] = list(sample[\"output\"].values()) if task_name == \"EyeNetPosition\" else list(sample[\"output\"].values())[0]\n",
    "            \n",
    "            sr = int(1 / (df[time_col].iloc[1] - df[time_col].iloc[0]))\n",
    "            srs[num_samples] = sr\n",
    "            durs[num_samples] = len(df) / sr\n",
    "\n",
    "            df.columns = [get_generic_channel_name(col) for col in df.columns]\n",
    "\n",
    "            valid_channels = set(df.columns) & set(task_channels)\n",
    "            all_channels &= valid_channels  # Intersect with previously seen channels\n",
    "            channels[num_samples] = sorted(valid_channels, key=lambda x: list(task_channels).index(x))\n",
    "            df = df[channels[num_samples]].astype(float)\n",
    "            data[num_samples] = torch.tensor(df.to_numpy(), dtype=torch.float32).T\n",
    "            \n",
    "            num_samples += 1\n",
    "            \n",
    "            del df\n",
    "            if num_samples % 100 == 0:\n",
    "                gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process sample: {sample}. Error: {e}\", file=sys.stderr)\n",
    "            failed_samples.append(sample)\n",
    "\n",
    "    return data, outputs, srs, durs, channels, all_channels\n",
    "\n",
    "\n",
    "print(f\"Preparing local paths...\")\n",
    "index_patterns = [\"/dev/shm/mae/index_*.json\", \"/scratch/mae/index_*.json\"]\n",
    "node_index = get_node_index(index_patterns=index_patterns)\n",
    "filename_to_nodepath = {os.path.basename(ie[\"origin_path\"]): ie[\"new_path\"] for trial_idx, ie in node_index.items()}\n",
    "filename_to_nodepath = {}\n",
    "print(f\"Prepared local paths. {len(filename_to_nodepath)} files found on node.\")\n",
    "\n",
    "# TODO: parallelize\n",
    "if load_mode != 1:\n",
    "    train_index, test_index = load_index0(json_path)\n",
    "    train_index, test_index = truncate0(train_index, test_index, num_keep, truncate)\n",
    "    \n",
    "    print(\"=\" * 10 + \"Load train data\" + \"=\" * 100)\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_all_channels = (\n",
    "        load_file_data(train_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load test data\" + \"=\" * 101)\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_all_channels = (\n",
    "        load_file_data(test_index, task_channels, filename_to_nodepath, load_mode, task_name, time_col)\n",
    "    )\n",
    "    common_channels = train_all_channels & test_all_channels\n",
    "    assert len(common_channels) > 0, \"No common channel found across samples!\"\n",
    "    print(f\"Common Channels: {common_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7502a-6b61-4828-bf1c-e7b8f5cddc66",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f65a6-9ecf-4f1a-89cd-7ac4d06c8757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc108915",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a4ad85-e544-4be1-8061-a1dd64d985c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor, target_height, target_width):\n",
    "    current_height, current_width = tensor.shape\n",
    "\n",
    "    if current_height < target_height:\n",
    "        padding_height = target_height - current_height\n",
    "        padding = torch.zeros((padding_height, current_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=0)\n",
    "    else:\n",
    "        tensor = tensor[:target_height, :]\n",
    "\n",
    "    if current_width < target_width:\n",
    "        padding_width = target_width - current_width\n",
    "        padding = torch.zeros((tensor.shape[0], padding_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=1)\n",
    "    else:\n",
    "        tensor = tensor[:, :target_width]\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def resample_signals(data, srs, target_sfreq):\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Resampling signals\"):\n",
    "        signal_numpy = signal.numpy().astype(np.float64)\n",
    "\n",
    "        # Perform resampling\n",
    "        signal_resampled = mne.filter.resample(signal_numpy, up=target_sfreq / srs[idx], npad='auto', window='boxcar', n_jobs=1)\n",
    "        \n",
    "        # Update the dictionary entry in-place\n",
    "        data[idx] = torch.tensor(signal_resampled, dtype=torch.float32)\n",
    "        \n",
    "        # Free memory\n",
    "        del signal_numpy, signal_resampled  # signal_resampled is deleted after assignment to tensor\n",
    "        if idx % 10 == 0:  # More frequent garbage collection for large data\n",
    "            gc.collect()\n",
    "            \n",
    "    return data  # This return is optional, as we are modifying the data dictionary in-place\n",
    "\n",
    "def pad_or_truncate_signals(data, common_length):\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Pad/Truncate signals\"):\n",
    "        signal_length = signal.shape[1]\n",
    "        if signal_length < common_length:\n",
    "            pad_width = common_length - signal_length\n",
    "            signal_padded = np.pad(signal, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        else:\n",
    "            signal_padded = signal[:, :common_length]\n",
    "        data[idx] = torch.tensor(signal_padded, dtype=torch.float32)\n",
    "        del signal, signal_padded  # Free memory\n",
    "        if idx % 100 == 0:\n",
    "            gc.collect()\n",
    "    return data\n",
    "\n",
    "def create_epochs(data, outputs, channels, sfreq=1000, is_classification=True):\n",
    "    events = []\n",
    "    event_id = {}\n",
    "    epochs_data = []\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Creating epochs\"):\n",
    "        epochs_data.append(signal.numpy())\n",
    "        if is_classification:\n",
    "            if outputs[idx] not in event_id:\n",
    "                event_id[outputs[idx]] = len(event_id) + 1\n",
    "            events.append([idx, 0, event_id[outputs[idx]]])\n",
    "        else:\n",
    "            events.append([idx, 0, 1])\n",
    "    events = np.array(events, dtype=int)\n",
    "    info = mne.create_info(\n",
    "        ch_names=channels, sfreq=sfreq, ch_types=\"eeg\"\n",
    "    )\n",
    "    epochs = mne.EpochsArray(\n",
    "        np.array(epochs_data),\n",
    "        info,\n",
    "        events=events,\n",
    "        event_id=event_id if is_classification else None,\n",
    "    )\n",
    "    del events, info, epochs_data  # Free memory\n",
    "    gc.collect()  # Explicitly invoke garbage collection\n",
    "    return epochs\n",
    "\n",
    "def pad_data(data, target_height, target_width):\n",
    "    padded_data = {}\n",
    "    for k, signals in tqdm(data.items(), desc=\"Padding data\"):\n",
    "        padded_data[k] = pad_tensor(signals, target_height, target_width)\n",
    "    return padded_data\n",
    "\n",
    "def filter_channels_by_indices(data, channels, common_channels):\n",
    "    filtered_data = {}\n",
    "    for k, signals in tqdm(data.items(), desc=\"Collect common channels\"):\n",
    "        common_channel_indices = [i for i, ch in enumerate(channels[k]) if ch in common_channels]\n",
    "        filtered_data[k] = signals[common_channel_indices, :]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387a9b7-5b7a-45ad-9f9e-4136aa5f3541",
   "metadata": {},
   "source": [
    "### Apply xDAWN Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87ea15d2-0db4-448e-b1dc-90e0206b4184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect common channels: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:00<00:00, 22757.91it/s]\n",
      "Collect common channels: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 22148.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sampling Frequency: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling signals: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:03<00:00, 124.11it/s]\n",
      "Resampling signals: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 91.58it/s]\n",
      "Pad/Truncate signals:   0%|▍                                                                                                                                                                                                         | 1/442 [00:00<04:06,  1.79it/s]/tmp/ipykernel_1927658/1523345857.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data[idx] = torch.tensor(signal_padded, dtype=torch.float32)\n",
      "Pad/Truncate signals: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:02<00:00, 152.13it/s]\n",
      "Pad/Truncate signals: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 120.60it/s]\n",
      "Creating epochs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442/442 [00:00<00:00, 257269.27it/s]\n",
      "Creating epochs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 192964.78it/s]\n",
      "Start fitting Xdawn...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xdawn({'correct_overlap': False, 'n_components': 2, 'reg': 0.1, 'signal_cov': None})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/src/models/components/Baselines\")\n",
    "\n",
    "# Filter data by common channels\n",
    "train_data_filtered = filter_channels_by_indices(train_data, train_channels, common_channels)\n",
    "test_data_filtered = filter_channels_by_indices(test_data, test_channels, common_channels)\n",
    "\n",
    "# Resample signals\n",
    "target_sfreq = int(max(list(train_sr.values()) + list(test_sr.values())))\n",
    "print(f\"Target Sampling Frequency: {target_sfreq}\")\n",
    "\n",
    "train_data_resampled = resample_signals(train_data_filtered, train_sr, target_sfreq)\n",
    "test_data_resampled = resample_signals(test_data_filtered, test_sr, target_sfreq)\n",
    "del train_data_filtered, test_data_filtered  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "# Get duration and channel counts for padding/truncating\n",
    "durs = [signals_tensor.shape[1] for idx, signals_tensor in train_data_resampled.items()] + [signals_tensor.shape[1] for idx, signals_tensor in test_data_resampled.items()]\n",
    "dur_90 = int(np.percentile(durs, 90))\n",
    "common_length = dur_90\n",
    "\n",
    "# Pad and truncate signals\n",
    "train_data_padded = pad_or_truncate_signals(train_data_resampled, common_length)\n",
    "test_data_padded = pad_or_truncate_signals(test_data_resampled, common_length)\n",
    "del train_data_resampled, test_data_resampled  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "is_classification = True if task_type == \"Classification\" else False\n",
    "epochs_train = create_epochs(\n",
    "    train_data_padded, train_outputs, list(common_channels), target_sfreq, is_classification\n",
    ")\n",
    "epochs_test = create_epochs( \n",
    "    test_data_padded, test_outputs, list(common_channels), target_sfreq, is_classification\n",
    ")\n",
    "del train_data_padded, test_data_padded  # Free memory\n",
    "gc.collect()  # Explicitly invoke garbage collection\n",
    "\n",
    "print(\"Start fitting Xdawn...\", file=sys.stderr)\n",
    "\n",
    "xdawn = Xdawn(n_components=2, correct_overlap=False, reg=0.1)\n",
    "xdawn.fit(epochs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778e0ab-d9b2-444e-8f8a-ebd4b2ff8ceb",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e08dd",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b9cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(train_outputs, test_outputs, is_classification):\n",
    "    if is_classification:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = label_encoder.fit_transform(list(train_outputs.values()))\n",
    "        y_test = label_encoder.transform(list(test_outputs.values()))\n",
    "    else:\n",
    "        y_train = np.array(list(train_outputs.values()))\n",
    "        y_test = np.array(list(test_outputs.values()))\n",
    "    return y_train, y_test\n",
    "\n",
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "simple_models = {\n",
    "    \"Classification\": {\n",
    "        \"LDA\": LinearDiscriminantAnalysis(),\n",
    "        \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "        \"Linear SVM\": SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "        \"RBF SVM\": SVC(gamma=2, C=1, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge Regression\": Ridge(alpha=1.0, random_state=42),\n",
    "        \"K-Nearest Neighbors Regressor\": KNeighborsRegressor(n_neighbors=3),\n",
    "        \"Support Vector Regression (Linear)\": SVR(kernel='linear', C=1.0),\n",
    "        \"Support Vector Regression (RBF)\": SVR(kernel='rbf', C=1.0, gamma=0.1),\n",
    "        \"Decision Tree Regressor\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "        \"Random Forest Regressor\": RandomForestRegressor(\n",
    "            max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "scores = {\n",
    "    \"Classification\": {\n",
    "        \"Accuracy\": accuracy_score,\n",
    "        \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "        \"Precision\": partial(precision_score, zero_division=np.nan),\n",
    "        \"Recall\": partial(recall_score, zero_division=np.nan),\n",
    "        \"F1 Score\": partial(f1_score, zero_division=np.nan),\n",
    "        \"ROC AUC\": roc_auc_score,\n",
    "        \"Confusion Matrix\": confusion_matrix,\n",
    "    },\n",
    "    \"Regression\": {\n",
    "        \"MAE\": mean_absolute_error,\n",
    "        \"RMSE\": lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False),  # Using lambda for RMSE\n",
    "        \"R-squared\": r2_score,\n",
    "        \"MAPE\": mean_absolute_percentage_error,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adaa5fd",
   "metadata": {},
   "source": [
    "### Actual Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10e692-f09f-499a-bcef-a74abba07cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = f'/itet-stor/maxihuber/net_scratch/finetune_models/{class_name}/{task_name}'\n",
    "scores_dir = f'/itet-stor/maxihuber/net_scratch/finetune_scores/{class_name}/{task_name}'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(scores_dir, exist_ok=True)\n",
    "\n",
    "# Transform the data using xDAWN\n",
    "X_train_xdawn = xdawn.transform(epochs_train)\n",
    "X_test_xdawn = xdawn.transform(epochs_test)\n",
    "\n",
    "# Flatten the transformed data for LDA input\n",
    "n_epochs_train, n_components, n_times = X_train_xdawn.shape\n",
    "X_train_xdawn = X_train_xdawn.reshape(n_epochs_train, n_components * n_times)\n",
    "n_epochs_test, n_components, n_times = X_test_xdawn.shape\n",
    "X_test_xdawn = X_test_xdawn.reshape(n_epochs_test, n_components * n_times)\n",
    "\n",
    "y_train, y_test = get_labels(train_outputs, test_outputs, is_classification)\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Training set class distribution:\", Counter(y_train))\n",
    "print(\"Test set class distribution:\", Counter(y_test))\n",
    "\n",
    "# Initialize a list to store the scores\n",
    "scores_list = []\n",
    "\n",
    "for name, clf in simple_models[task_type].items():\n",
    "    print(\"=\" * 10 + f\"{name} Model\" + \"=\" * 100, file=sys.stderr)\n",
    "    \n",
    "    if name == \"XGBoost\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_xdawn)\n",
    "        X_test_scaled = scaler.transform(X_test_xdawn)\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "    else:\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train_xdawn, y_train)\n",
    "\n",
    "    # Store the fitted predictor for later use\n",
    "    if name == \"XGBoost\":\n",
    "        model_path = os.path.join(models_dir, f\"{name}_model.json\")\n",
    "        clf.save_model(model_path)\n",
    "    else:\n",
    "        model_path = os.path.join(models_dir, f\"{name}_model.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(clf, f)\n",
    "\n",
    "    y_pred = clf.predict(X_test_xdawn)\n",
    "\n",
    "    model_scores = {'Model': name}\n",
    "    for score_name, score_func in scores[task_type].items():\n",
    "        score = score_func(y_test, y_pred)\n",
    "        model_scores[score_name] = score\n",
    "        # print(f\"{score_name}: {score} ({name})\", file=sys.stderr)\n",
    "\n",
    "    # Store the scores for later use\n",
    "    scores_list.append(model_scores)\n",
    "\n",
    "    # Clean up to save memory\n",
    "    del clf, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "# Convert the scores list to a DataFrame and save it\n",
    "scores_df = pd.DataFrame(scores_list)\n",
    "scores_path = os.path.join(scores_dir, \"model_scores.csv\")\n",
    "scores_df.to_csv(scores_path, index=False)\n",
    "print(f\"Stored scores at {scores_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
